================================================================================
                    VOLLEYBALL ANALYTICS PIPELINE
                    Complete Architecture Documentation
================================================================================

                         Created: December 2024
                         Version: 1.0

================================================================================
                           TABLE OF CONTENTS
================================================================================

    1.  SYSTEM-LEVEL ARCHITECTURE
        1.1  High-Level Overview
        1.2  Component Stack
        1.3  Data Flow Types
        1.4  File Structure

    2.  PIPELINE STAGES OVERVIEW
        2.1  Stage Sequence
        2.2  Stage Responsibilities
        2.3  Progress Tracking

    3.  INDIVIDUAL WORKFLOW DOCUMENTATION
        3.1  Video Input & Loading
        3.2  Player Detection
        3.3  Player Tracking
        3.4  Pose Estimation
        3.5  Action Classification
        3.6  Segment Extraction
        3.7  Post-Processing
        3.8  Export & Analytics

    4.  DEEP TASK BREAKDOWNS
        4.1  Detection Deep Dive
        4.2  Tracking Deep Dive (ByteTrack)
        4.3  Pose Estimation Deep Dive (MediaPipe)
        4.4  Action Classification Deep Dive
        4.5  Segment Extraction Deep Dive
        4.6  Track Merging Deep Dive

    5.  DATA TYPES REFERENCE
        5.1  Core Enums
        5.2  Data Classes
        5.3  Type Mappings

    6.  CONFIGURATION REFERENCE

================================================================================
                    1. SYSTEM-LEVEL ARCHITECTURE
================================================================================

1.1 HIGH-LEVEL OVERVIEW
--------------------------------------------------------------------------------

The Volleyball Analytics Pipeline is a modular video analysis system that
processes volleyball footage to detect and classify player actions.

INPUT:  Video file (MP4, MOV, etc.)
OUTPUT: Action segments (JSON), Statistics, HTML Reports

                    ┌─────────────────────────────────────────────┐
                    │             VIDEO INPUT FILE                │
                    │         (Rithika_Training.MOV)              │
                    └─────────────────────────────────────────────┘
                                        │
                                        ▼
┌───────────────────────────────────────────────────────────────────────────────┐
│                                                                               │
│                          FRAME-BY-FRAME PROCESSING                            │
│                                                                               │
│   ┌───────────┐    ┌───────────┐    ┌───────────┐    ┌───────────────────┐   │
│   │ DETECTION │───▶│ TRACKING  │───▶│   POSE    │───▶│ ACTION CLASSIFIER │   │
│   │  (YOLO)   │    │(ByteTrack)│    │(MediaPipe)│    │   (Rule-Based)    │   │
│   └───────────┘    └───────────┘    └───────────┘    └───────────────────┘   │
│        │                │                │                     │              │
│        ▼                ▼                ▼                     ▼              │
│   Detections      TrackedPerson      PoseResult          ActionResult        │
│                                                                               │
└───────────────────────────────────────────────────────────────────────────────┘
                                        │
                                        ▼
┌───────────────────────────────────────────────────────────────────────────────┐
│                         SEGMENT EXTRACTION                                    │
│              (Groups frame-level predictions into temporal segments)          │
└───────────────────────────────────────────────────────────────────────────────┘
                                        │
                                        ▼
┌───────────────────────────────────────────────────────────────────────────────┐
│                          POST-PROCESSING                                      │
│   ┌─────────────────────────┐    ┌─────────────────────────────────────────┐  │
│   │     Track Merging       │───▶│     Statistics & Analytics              │  │
│   │  (Consolidate Player    │    │  (Per-player stats, action counts,     │  │
│   │   IDs across video)     │    │   actions per minute, etc.)            │  │
│   └─────────────────────────┘    └─────────────────────────────────────────┘  │
└───────────────────────────────────────────────────────────────────────────────┘
                                        │
                                        ▼
┌───────────────────────────────────────────────────────────────────────────────┐
│                              OUTPUT FILES                                     │
│                                                                               │
│   ┌──────────────────┐  ┌──────────────────┐  ┌──────────────────────────┐   │
│   │  segments.jsonl  │  │   summary.json   │  │    player_stats.json     │   │
│   │ (All action      │  │ (Video stats,    │  │ (Per-player action       │   │
│   │  segments with   │  │  total actions,  │  │  counts, time on         │   │
│   │  timestamps)     │  │  duration, etc.) │  │  court, etc.)            │   │
│   └──────────────────┘  └──────────────────┘  └──────────────────────────┘   │
│                                                                               │
│   ┌──────────────────────────────────────────────────────────────────────┐   │
│   │                         report.html                                   │   │
│   │            (Visual HTML report with charts and timeline)              │   │
│   └──────────────────────────────────────────────────────────────────────┘   │
└───────────────────────────────────────────────────────────────────────────────┘


1.2 COMPONENT STACK
--------------------------------------------------------------------------------

Pipeline (Orchestrator)
│
├── VideoReader (video_io/)
│   └── Reads video frames as numpy arrays (BGR format)
│
├── VideoStabilizer (stabilization/) [Optional]
│   └── Stabilizes shaky camera footage
│
├── PlayerTracker (detection_tracking/)
│   │
│   ├── PlayerDetector
│   │   └── YOLO v8 - Detects person bounding boxes
│   │
│   ├── ByteTracker
│   │   └── Assigns persistent track_ids across frames
│   │
│   └── CourtDetector [Optional]
│       └── Filters detections to court area
│
├── PoseEstimator (pose/)
│   └── MediaPipe Pose
│       └── Extracts 33 body keypoints per person
│
├── ActionClassifier (actions/)
│   └── Rule-based classifier
│       └── Analyzes pose features → classifies action
│
├── SegmentExtractor (segments/)
│   └── Converts frame-level actions → temporal segments
│
├── TrackMerger (segments/)
│   └── Consolidates fragmented track IDs
│
└── SegmentStore / Analytics (analytics/)
    └── Computes statistics & exports results


1.3 DATA FLOW TYPES
--------------------------------------------------------------------------------

Each stage transforms data from one type to the next:

┌────────────────────┐
│  Frame             │  numpy.ndarray (BGR image, HxWx3)
│  (np.ndarray)      │  Raw pixel data from video
└────────────────────┘
          │
          ▼
┌────────────────────┐
│  Detection         │  BoundingBox + confidence + class_id
│                    │  Where people are in the frame
└────────────────────┘
          │
          ▼
┌────────────────────┐
│  TrackedPerson     │  Detection + track_id + age + is_confirmed
│                    │  Consistent identity across frames
└────────────────────┘
          │
          ▼
┌────────────────────┐
│  PoseResult        │  Skeleton (33 keypoints) + track_id
│                    │  Body joint positions for each person
└────────────────────┘
          │
          ▼
┌────────────────────┐
│  ActionResult      │  ActionType + confidence + features
│                    │  What action is being performed
└────────────────────┘
          │
          ▼
┌────────────────────┐
│  FrameAction       │  ActionResult + frame_index + timestamp
│  Prediction        │  Per-frame action with timing info
└────────────────────┘
          │
          ▼
┌────────────────────┐
│  ActionSegment     │  Action + start_time + end_time + player_id
│                    │  Temporal range of continuous action
└────────────────────┘
          │
          ▼
┌────────────────────┐
│  PipelineResult    │  All segments + statistics + file paths
│                    │  Final output package
└────────────────────┘


1.4 FILE STRUCTURE
--------------------------------------------------------------------------------

volley_analytics/
│
├── __init__.py              # Package exports
│
├── pipeline/
│   ├── __init__.py
│   └── pipeline.py          # Main Pipeline class, orchestrates all stages
│
├── video_io/
│   ├── __init__.py
│   ├── reader.py            # VideoReader - reads frames from video files
│   └── writer.py            # VideoWriter - writes annotated output videos
│
├── stabilization/
│   ├── __init__.py
│   └── stabilizer.py        # VideoStabilizer - camera shake correction
│
├── detection_tracking/
│   ├── __init__.py
│   ├── detector.py          # PlayerDetector - YOLO v8 person detection
│   ├── tracker.py           # PlayerTracker - combines detection + tracking
│   └── bytetrack.py         # ByteTracker - multi-object tracking algorithm
│
├── court/
│   ├── __init__.py
│   └── detector.py          # CourtDetector - court line detection
│
├── pose/
│   ├── __init__.py
│   └── estimator.py         # PoseEstimator - MediaPipe pose extraction
│
├── actions/
│   ├── __init__.py
│   └── classifier.py        # ActionClassifier - rule-based action detection
│
├── segments/
│   ├── __init__.py
│   ├── extractor.py         # SegmentExtractor - creates ActionSegments
│   └── track_merger.py      # TrackMerger - consolidates player track IDs
│
├── analytics/
│   ├── __init__.py
│   ├── stats.py             # VideoStats, PlayerStats computation
│   └── store.py             # SegmentStore - segment storage & queries
│
├── visualization/
│   ├── __init__.py
│   └── report.py            # HTML report generation
│
└── common/
    ├── __init__.py
    ├── data_types.py        # All shared data types (enums, models)
    └── config.py            # PipelineConfig and sub-configs


================================================================================
                    2. PIPELINE STAGES OVERVIEW
================================================================================

2.1 STAGE SEQUENCE
--------------------------------------------------------------------------------

The pipeline processes video through these stages in order:

    ┌─────────────────────────────────────────────────────────────────────────┐
    │  Stage 1: INIT                                                          │
    │  ─────────────────────────────────────────────────────────────────────  │
    │  • Validate video file exists                                           │
    │  • Get video metadata (frames, fps, duration)                           │
    │  • Create output directory                                              │
    │  • Initialize progress tracking                                         │
    │                                                                         │
    │  File: pipeline/pipeline.py:290-332                                     │
    └─────────────────────────────────────────────────────────────────────────┘
                                        │
                                        ▼
    ┌─────────────────────────────────────────────────────────────────────────┐
    │  Stage 2: STABILIZATION (Optional)                                      │
    │  ─────────────────────────────────────────────────────────────────────  │
    │  • Estimate camera motion between frames                                │
    │  • Apply stabilization transforms                                       │
    │  • Crop borders to remove edge artifacts                                │
    │                                                                         │
    │  File: stabilization/stabilizer.py                                      │
    │  Note: Currently disabled in default pipeline                           │
    └─────────────────────────────────────────────────────────────────────────┘
                                        │
                                        ▼
    ┌─────────────────────────────────────────────────────────────────────────┐
    │  Stage 3: DETECTION                                                     │
    │  ─────────────────────────────────────────────────────────────────────  │
    │  • Run YOLO v8 on each frame                                            │
    │  • Filter by confidence threshold (default 0.4)                         │
    │  • Filter by size (remove too small/large detections)                   │
    │  • Filter by position (remove edge detections)                          │
    │  • Optional: Filter by court boundaries                                 │
    │                                                                         │
    │  File: detection_tracking/detector.py                                   │
    │  Output: List[Detection] per frame                                      │
    └─────────────────────────────────────────────────────────────────────────┘
                                        │
                                        ▼
    ┌─────────────────────────────────────────────────────────────────────────┐
    │  Stage 4: TRACKING                                                      │
    │  ─────────────────────────────────────────────────────────────────────  │
    │  • ByteTrack algorithm assigns persistent IDs                           │
    │  • Maintains track buffer for lost players (150 frames = 5 sec)         │
    │  • Re-ID using color histograms for track recovery                      │
    │  • Filters tentative vs confirmed tracks                                │
    │                                                                         │
    │  File: detection_tracking/tracker.py, detection_tracking/bytetrack.py   │
    │  Output: List[TrackedPerson] per frame                                  │
    └─────────────────────────────────────────────────────────────────────────┘
                                        │
                                        ▼
    ┌─────────────────────────────────────────────────────────────────────────┐
    │  Stage 5: POSE ESTIMATION                                               │
    │  ─────────────────────────────────────────────────────────────────────  │
    │  • Crop player bounding box (with padding)                              │
    │  • Run MediaPipe Pose on each crop                                      │
    │  • Extract 33 body keypoints with visibility                            │
    │  • Calculate skeleton confidence                                        │
    │                                                                         │
    │  File: pose/estimator.py                                                │
    │  Output: List[PoseResult] per frame                                     │
    └─────────────────────────────────────────────────────────────────────────┘
                                        │
                                        ▼
    ┌─────────────────────────────────────────────────────────────────────────┐
    │  Stage 6: ACTION CLASSIFICATION                                         │
    │  ─────────────────────────────────────────────────────────────────────  │
    │  • Extract pose features (hand heights, knee angles, etc.)              │
    │  • Apply rule-based decision tree                                       │
    │  • Temporal smoothing (5-frame history)                                 │
    │  • Map classifier actions to common ActionType enum                     │
    │                                                                         │
    │  File: actions/classifier.py                                            │
    │  Output: ActionResult per (frame, player)                               │
    └─────────────────────────────────────────────────────────────────────────┘
                                        │
                                        ▼
    ┌─────────────────────────────────────────────────────────────────────────┐
    │  Stage 7: SEGMENT EXTRACTION                                            │
    │  ─────────────────────────────────────────────────────────────────────  │
    │  • Track active segments per player                                     │
    │  • Detect action boundaries (when action changes)                       │
    │  • Accumulate confidence scores                                         │
    │  • Filter by minimum duration (5 frames)                                │
    │  • Merge consecutive same-action segments                               │
    │                                                                         │
    │  File: segments/extractor.py                                            │
    │  Output: List[ActionSegment]                                            │
    └─────────────────────────────────────────────────────────────────────────┘
                                        │
                                        ▼
    ┌─────────────────────────────────────────────────────────────────────────┐
    │  Stage 8: POST-PROCESSING                                               │
    │  ─────────────────────────────────────────────────────────────────────  │
    │  • Track merging (consolidate fragmented IDs to max_players)            │
    │  • Activity-based merging (group by serve counts)                       │
    │  • Compute final statistics                                             │
    │                                                                         │
    │  File: segments/track_merger.py, analytics/stats.py                     │
    └─────────────────────────────────────────────────────────────────────────┘
                                        │
                                        ▼
    ┌─────────────────────────────────────────────────────────────────────────┐
    │  Stage 9: EXPORT                                                        │
    │  ─────────────────────────────────────────────────────────────────────  │
    │  • segments.jsonl - All action segments                                 │
    │  • summary.json - Video-level statistics                                │
    │  • player_stats.json - Per-player breakdown                             │
    │  • report.html - Visual HTML report (optional)                          │
    │  • annotated.mp4 - Video with overlays (optional)                       │
    │                                                                         │
    │  File: pipeline/pipeline.py:559-604, visualization/report.py            │
    └─────────────────────────────────────────────────────────────────────────┘


2.2 STAGE RESPONSIBILITIES
--------------------------------------------------------------------------------

┌──────────────┬──────────────────────────────────────────────────────────────┐
│    Stage     │                      Responsibility                          │
├──────────────┼──────────────────────────────────────────────────────────────┤
│ INIT         │ Setup: validate inputs, get video info, create directories   │
│ STABILIZE    │ Correct camera shake (optional, not in default config)       │
│ DETECTION    │ Find people in each frame using YOLO                         │
│ TRACKING     │ Assign consistent IDs across frames using ByteTrack          │
│ POSE         │ Extract body keypoints using MediaPipe                       │
│ ACTION       │ Classify what action each person is doing                    │
│ SEGMENT      │ Group consecutive frames into action segments                │
│ ANALYTICS    │ Compute statistics (per-player, per-action, etc.)            │
│ EXPORT       │ Write output files (JSONL, JSON, HTML)                       │
└──────────────┴──────────────────────────────────────────────────────────────┘


2.3 PROGRESS TRACKING
--------------------------------------------------------------------------------

The pipeline reports progress through a callback function:

    PipelineProgress:
    ├── stage: PipelineStage        # Current stage (DETECTION, POSE, etc.)
    ├── frame_index: int            # Current frame being processed
    ├── total_frames: int           # Total frames in video
    ├── stage_progress: float       # 0.0 - 1.0 within current stage
    ├── overall_progress: float     # 0.0 - 1.0 across all stages
    ├── fps: float                  # Processing speed (frames/second)
    ├── eta_seconds: float          # Estimated time remaining
    └── message: str                # Human-readable status

Example progress callback:

    def on_progress(p):
        bar = "█" * int(30 * p.overall_progress)
        print(f"[{bar}] {p.percent}% {p.stage.value}")


================================================================================
                    3. INDIVIDUAL WORKFLOW DOCUMENTATION
================================================================================

3.1 VIDEO INPUT & LOADING
--------------------------------------------------------------------------------

File: video_io/reader.py

┌─────────────────────────────────────────────────────────────────────────────┐
│                           VIDEO READER WORKFLOW                             │
└─────────────────────────────────────────────────────────────────────────────┘

    Input:  Video file path (str or Path)
    Output: Generator of numpy frames (BGR, HxWx3)

    ┌──────────────────┐
    │  Open Video File │
    │  cv2.VideoCapture│
    └────────┬─────────┘
             │
             ▼
    ┌──────────────────┐
    │ Get Video Info   │
    │ • frame_count    │
    │ • fps            │
    │ • width, height  │
    │ • duration       │
    └────────┬─────────┘
             │
             ▼
    ┌──────────────────┐
    │  Frame Loop      │──────────────────────────────────────────┐
    │  cap.read()      │                                          │
    └────────┬─────────┘                                          │
             │                                                     │
             ▼                                                     │
    ┌──────────────────┐                                          │
    │  Yield Frame     │                                          │
    │  as np.ndarray   │────────────────────────────────────────▶│
    │  (BGR)           │                                       LOOP
    └──────────────────┘                                          │
             │                                                     │
             ▼                                                     │
    ┌──────────────────┐                                          │
    │  End of Video?   │──── No ──────────────────────────────────┘
    └────────┬─────────┘
             │ Yes
             ▼
    ┌──────────────────┐
    │  Close Capture   │
    │  cap.release()   │
    └──────────────────┘


3.2 PLAYER DETECTION
--------------------------------------------------------------------------------

File: detection_tracking/detector.py

┌─────────────────────────────────────────────────────────────────────────────┐
│                        PLAYER DETECTION WORKFLOW                            │
└─────────────────────────────────────────────────────────────────────────────┘

    Input:  BGR frame (np.ndarray)
    Output: List[Detection] - bounding boxes with confidence

    ┌──────────────────────────┐
    │     Input Frame          │
    │   (1920x1080 BGR)        │
    └───────────┬──────────────┘
                │
                ▼
    ┌──────────────────────────┐
    │   YOLO v8 Inference      │
    │   model.predict(frame)   │
    │                          │
    │   Model: yolov8n.pt      │
    │   (nano - fastest)       │
    │                          │
    │   Output: boxes, scores, │
    │   class_ids              │
    └───────────┬──────────────┘
                │
                ▼
    ┌──────────────────────────┐
    │  Filter by Class         │
    │  Keep only class_id=0    │
    │  (person in COCO)        │
    └───────────┬──────────────┘
                │
                ▼
    ┌──────────────────────────┐
    │  Filter by Confidence    │
    │  Keep conf >= 0.4        │
    │  (configurable)          │
    └───────────┬──────────────┘
                │
                ▼
    ┌──────────────────────────┐
    │  Filter by Size          │
    │  • min_area: 1000px²     │
    │  • max_area: 50% frame   │
    │  • aspect_ratio: 0.2-2.0 │
    └───────────┬──────────────┘
                │
                ▼
    ┌──────────────────────────┐
    │  Filter by Position      │
    │  Remove edge detections  │
    │  (within 5% of borders)  │
    └───────────┬──────────────┘
                │
                ▼
    ┌──────────────────────────┐
    │  Create Detection        │
    │  Objects                 │
    │                          │
    │  Detection:              │
    │  • bbox: BoundingBox     │
    │  • confidence: float     │
    │  • class_id: 0           │
    │  • class_name: "person"  │
    └───────────┬──────────────┘
                │
                ▼
    ┌──────────────────────────┐
    │  Return List[Detection]  │
    └──────────────────────────┘


3.3 PLAYER TRACKING
--------------------------------------------------------------------------------

File: detection_tracking/tracker.py, detection_tracking/bytetrack.py

┌─────────────────────────────────────────────────────────────────────────────┐
│                         PLAYER TRACKING WORKFLOW                            │
└─────────────────────────────────────────────────────────────────────────────┘

    Input:  List[Detection] for current frame
    Output: List[TrackedPerson] with persistent track_ids

    ┌──────────────────────────┐
    │   Current Frame          │
    │   Detections             │
    │   [Det1, Det2, Det3]     │
    └───────────┬──────────────┘
                │
                ▼
    ┌──────────────────────────────────────────────────────────────────────┐
    │                         BYTETRACK ALGORITHM                          │
    │                                                                      │
    │   ┌────────────────────┐    ┌────────────────────┐                   │
    │   │  Existing Tracks   │    │  New Detections    │                   │
    │   │  [T1, T2, T3, T4]  │    │  [D1, D2, D3]      │                   │
    │   └─────────┬──────────┘    └──────────┬─────────┘                   │
    │             │                          │                              │
    │             └──────────┬───────────────┘                              │
    │                        │                                              │
    │                        ▼                                              │
    │   ┌────────────────────────────────────────────────────────────────┐ │
    │   │           STEP 1: HIGH-CONFIDENCE MATCHING                     │ │
    │   │                                                                │ │
    │   │  • Take detections with conf >= 0.5                            │ │
    │   │  • Compute IoU matrix between high-conf dets and tracks        │ │
    │   │  • Hungarian algorithm for optimal assignment                  │ │
    │   │  • Match if IoU >= 0.3                                         │ │
    │   │                                                                │ │
    │   │  Matched: T1↔D1, T2↔D2                                         │ │
    │   │  Unmatched tracks: T3, T4                                      │ │
    │   │  Unmatched dets: D3 (if high-conf)                             │ │
    │   └────────────────────────────────────────────────────────────────┘ │
    │                        │                                              │
    │                        ▼                                              │
    │   ┌────────────────────────────────────────────────────────────────┐ │
    │   │           STEP 2: LOW-CONFIDENCE MATCHING                      │ │
    │   │                                                                │ │
    │   │  • Take remaining detections (conf 0.1-0.5)                    │ │
    │   │  • Match against unmatched tracks (T3, T4)                     │ │
    │   │  • Helps recover occluded players                              │ │
    │   │                                                                │ │
    │   │  Matched: T3↔D_low                                             │ │
    │   │  Still unmatched: T4                                           │ │
    │   └────────────────────────────────────────────────────────────────┘ │
    │                        │                                              │
    │                        ▼                                              │
    │   ┌────────────────────────────────────────────────────────────────┐ │
    │   │           STEP 3: RE-ID MATCHING (Optional)                    │ │
    │   │                                                                │ │
    │   │  • For long-lost tracks, use appearance features               │ │
    │   │  • Extract color histogram from detection region               │ │
    │   │  • Compare with stored histograms for lost tracks              │ │
    │   │  • Match if similarity >= 0.6                                  │ │
    │   │                                                                │ │
    │   │  This recovers tracks when player leaves & returns             │ │
    │   └────────────────────────────────────────────────────────────────┘ │
    │                        │                                              │
    │                        ▼                                              │
    │   ┌────────────────────────────────────────────────────────────────┐ │
    │   │           STEP 4: CREATE NEW TRACKS                            │ │
    │   │                                                                │ │
    │   │  • Unmatched high-conf detections → new Track                  │ │
    │   │  • Assign new unique track_id                                  │ │
    │   │  • Mark as "tentative" (not confirmed)                         │ │
    │   └────────────────────────────────────────────────────────────────┘ │
    │                        │                                              │
    │                        ▼                                              │
    │   ┌────────────────────────────────────────────────────────────────┐ │
    │   │           STEP 5: UPDATE TRACK STATES                          │ │
    │   │                                                                │ │
    │   │  For matched tracks:                                           │ │
    │   │  • Update bbox with detection bbox                             │ │
    │   │  • Increment age                                               │ │
    │   │  • Reset time_since_update = 0                                 │ │
    │   │  • Update appearance histogram                                 │ │
    │   │  • If age >= min_hits → is_confirmed = True                    │ │
    │   │                                                                │ │
    │   │  For unmatched tracks:                                         │ │
    │   │  • Increment time_since_update                                 │ │
    │   │  • Predict bbox using Kalman filter                            │ │
    │   │  • If time_since_update > track_buffer → remove track          │ │
    │   └────────────────────────────────────────────────────────────────┘ │
    │                                                                      │
    └───────────────────────────────────────────────────────────────────────┘
                │
                ▼
    ┌──────────────────────────┐
    │  Convert to TrackedPerson│
    │                          │
    │  TrackedPerson:          │
    │  • track_id: 3           │
    │  • bbox: BoundingBox     │
    │  • det_conf: 0.85        │
    │  • frame_index: 150      │
    │  • timestamp: 5.0        │
    │  • track_age: 45         │
    │  • is_confirmed: True    │
    └───────────┬──────────────┘
                │
                ▼
    ┌──────────────────────────┐
    │  Return List[Tracked     │
    │  Person]                 │
    └──────────────────────────┘


Tracking Parameters:
────────────────────────────────────────────────────────────────────────────────
    track_thresh: 0.3       # Minimum detection confidence to create track
    track_buffer: 150       # Frames to keep lost track (5 sec at 30fps)
    match_thresh: 0.4       # IoU threshold for matching
    min_hits: 2             # Detections before track is "confirmed"
    max_tracks: 12          # Maximum simultaneous tracks
    use_reid: True          # Enable appearance-based re-identification
    reid_thresh: 0.6        # Appearance similarity threshold


3.4 POSE ESTIMATION
--------------------------------------------------------------------------------

File: pose/estimator.py

┌─────────────────────────────────────────────────────────────────────────────┐
│                        POSE ESTIMATION WORKFLOW                             │
└─────────────────────────────────────────────────────────────────────────────┘

    Input:  Frame + TrackedPerson (with bbox)
    Output: PoseResult with Skeleton (33 keypoints)

    ┌──────────────────────────┐
    │   TrackedPerson          │
    │   • track_id: 3          │
    │   • bbox: (100,50,       │
    │            200,300)      │
    └───────────┬──────────────┘
                │
                ▼
    ┌──────────────────────────┐
    │  Add Padding to BBox     │
    │  10% on each side        │
    │                          │
    │  Original: 100x250       │
    │  Padded:   120x275       │
    └───────────┬──────────────┘
                │
                ▼
    ┌──────────────────────────┐
    │  Crop Player Region      │
    │  from Full Frame         │
    │                          │
    │  frame[y1:y2, x1:x2]     │
    └───────────┬──────────────┘
                │
                ▼
    ┌──────────────────────────┐
    │  Convert BGR → RGB       │
    │  (MediaPipe requires)    │
    └───────────┬──────────────┘
                │
                ▼
    ┌────────────────────────────────────────────────────────────────────────┐
    │                     MEDIAPIPE POSE PROCESSING                          │
    │                                                                        │
    │  Model Complexity: 1 (full, 33 keypoints)                              │
    │  Static Image Mode: False (video tracking enabled)                     │
    │  Smooth Landmarks: True                                                │
    │                                                                        │
    │  ┌────────────────────────────────────────────────────────────────┐   │
    │  │  33 KEYPOINTS (MediaPipe BlazePose)                            │   │
    │  │                                                                │   │
    │  │       0: nose                                                  │   │
    │  │    1-6: left/right eye (inner, center, outer)                  │   │
    │  │    7-8: left/right ear                                         │   │
    │  │   9-10: mouth left/right                                       │   │
    │  │  11-12: left/right shoulder                                    │   │
    │  │  13-14: left/right elbow                                       │   │
    │  │  15-16: left/right wrist                                       │   │
    │  │  17-22: left/right pinky, index, thumb                         │   │
    │  │  23-24: left/right hip                                         │   │
    │  │  25-26: left/right knee                                        │   │
    │  │  27-28: left/right ankle                                       │   │
    │  │  29-30: left/right heel                                        │   │
    │  │  31-32: left/right foot index                                  │   │
    │  └────────────────────────────────────────────────────────────────┘   │
    │                                                                        │
    │  Output per keypoint:                                                  │
    │  • x, y: normalized (0-1) within crop                                  │
    │  • z: relative depth (smaller = closer to camera)                      │
    │  • visibility: confidence (0-1)                                        │
    │                                                                        │
    └────────────────────────────────────────────────────────────────────────┘
                │
                ▼
    ┌──────────────────────────┐
    │  Convert Normalized      │
    │  Coords → Pixel Coords   │
    │                          │
    │  px = crop_x1 + (norm_x  │
    │       * crop_width)      │
    └───────────┬──────────────┘
                │
                ▼
    ┌──────────────────────────┐
    │  Create Keypoint Objects │
    │                          │
    │  Keypoint:               │
    │  • x: 450.5 (pixels)     │
    │  • y: 320.2 (pixels)     │
    │  • z: -0.15 (depth)      │
    │  • visibility: 0.92      │
    │  • name: "LEFT_WRIST"    │
    └───────────┬──────────────┘
                │
                ▼
    ┌──────────────────────────┐
    │  Create Skeleton         │
    │                          │
    │  Skeleton:               │
    │  • keypoints: [33 kps]   │
    │  • confidence: 0.85      │
    │    (visible_count/total) │
    └───────────┬──────────────┘
                │
                ▼
    ┌──────────────────────────┐
    │  Return PoseResult       │
    │                          │
    │  PoseResult:             │
    │  • track_id: 3           │
    │  • skeleton: Skeleton    │
    │  • bbox: (100,50,200,300)│
    │  • frame_index: 150      │
    └──────────────────────────┘


Skeleton Helper Methods:
────────────────────────────────────────────────────────────────────────────────
    get_keypoint(idx)       # Get specific keypoint by index
    get_joint_angle(j1,j2,j3)  # Calculate angle at j2 (degrees)
    get_arm_angles()        # Get left/right elbow angles
    get_knee_angles()       # Get left/right knee angles
    get_hand_height()       # Get hand position relative to shoulders


3.5 ACTION CLASSIFICATION
--------------------------------------------------------------------------------

File: actions/classifier.py

┌─────────────────────────────────────────────────────────────────────────────┐
│                      ACTION CLASSIFICATION WORKFLOW                         │
└─────────────────────────────────────────────────────────────────────────────┘

    Input:  PoseResult (with Skeleton)
    Output: ActionResult (action type + confidence)

    ┌──────────────────────────┐
    │   PoseResult             │
    │   • skeleton with 33     │
    │     keypoints            │
    └───────────┬──────────────┘
                │
                ▼
    ┌────────────────────────────────────────────────────────────────────────┐
    │                     FEATURE EXTRACTION                                 │
    │                                                                        │
    │   From skeleton keypoints, extract:                                    │
    │                                                                        │
    │   HAND HEIGHTS (relative to shoulders, in pixels):                     │
    │   ┌────────────────────────────────────────────────────────────────┐  │
    │   │  left_hand_height  = left_shoulder.y - left_wrist.y            │  │
    │   │  right_hand_height = right_shoulder.y - right_wrist.y          │  │
    │   │  max_hand_height   = max(left, right)                          │  │
    │   │                                                                │  │
    │   │  Positive = hands above shoulders (serve, spike, block)        │  │
    │   │  Negative = hands below shoulders (dig, pass)                  │  │
    │   └────────────────────────────────────────────────────────────────┘  │
    │                                                                        │
    │   ARM ANGLES (degrees at elbow):                                       │
    │   ┌────────────────────────────────────────────────────────────────┐  │
    │   │  left_elbow_angle  = angle(shoulder, elbow, wrist)             │  │
    │   │  right_elbow_angle = angle(shoulder, elbow, wrist)             │  │
    │   │                                                                │  │
    │   │  180° = straight arm                                           │  │
    │   │  <120° = bent arm                                              │  │
    │   └────────────────────────────────────────────────────────────────┘  │
    │                                                                        │
    │   KNEE ANGLES (degrees, for crouch detection):                         │
    │   ┌────────────────────────────────────────────────────────────────┐  │
    │   │  left_knee_angle  = angle(hip, knee, ankle)                    │  │
    │   │  right_knee_angle = angle(hip, knee, ankle)                    │  │
    │   │  avg_knee_angle   = average of both                            │  │
    │   │                                                                │  │
    │   │  <140° = crouching (dig, receive)                              │  │
    │   │  <100° = deep crouch (dig)                                     │  │
    │   │  >150° = standing upright                                      │  │
    │   └────────────────────────────────────────────────────────────────┘  │
    │                                                                        │
    │   OTHER FEATURES:                                                      │
    │   ┌────────────────────────────────────────────────────────────────┐  │
    │   │  hands_together: distance between wrists < 100px               │  │
    │   │  hands_above_head: wrist.y < nose.y - 30px                     │  │
    │   │  arms_symmetry: 1 - (height_diff / max_height)                 │  │
    │   │  one_arm_high: significant asymmetry in arm heights            │  │
    │   │  standing_upright: avg_knee_angle > 150°                       │  │
    │   │  confidence: visible_keypoints / total_keypoints               │  │
    │   └────────────────────────────────────────────────────────────────┘  │
    │                                                                        │
    └────────────────────────────────────────────────────────────────────────┘
                │
                ▼
    ┌────────────────────────────────────────────────────────────────────────┐
    │                      DECISION TREE                                     │
    │                                                                        │
    │              ┌───────────────────────────┐                             │
    │              │  confidence < 0.3?        │                             │
    │              └─────────────┬─────────────┘                             │
    │                           │                                            │
    │                    Yes ───┼─── No                                      │
    │                     │     │     │                                      │
    │                     ▼           ▼                                      │
    │              ┌──────────┐  ┌─────────────────────────────────┐         │
    │              │ UNKNOWN  │  │  hands_above_head AND           │         │
    │              └──────────┘  │  max_hand_height > 100px?       │         │
    │                            └───────────────┬─────────────────┘         │
    │                                           │                            │
    │                                    Yes ───┼─── No                      │
    │                                     │     │     │                      │
    │                                     ▼           ▼                      │
    │               ┌─────────────────────────┐   (continue below)           │
    │               │  arms_symmetry > 0.7?   │                              │
    │               └───────────┬─────────────┘                              │
    │                          │                                             │
    │                   Yes ───┼─── No                                       │
    │                    │     │     │                                       │
    │                    ▼           ▼                                       │
    │              ┌──────────┐  ┌─────────────────┐                         │
    │              │  BLOCK   │  │ standing_upright?│                        │
    │              │ (0.8)    │  └────────┬────────┘                         │
    │              └──────────┘          │                                   │
    │                             Yes ───┼─── No                             │
    │                              │     │     │                             │
    │                              ▼           ▼                             │
    │                        ┌──────────┐  ┌──────────┐                      │
    │                        │  SERVE   │  │  SPIKE   │                      │
    │                        │ (0.75)   │  │ (0.7)    │                      │
    │                        └──────────┘  └──────────┘                      │
    │                                                                        │
    │   ... (if not hands above head, continue):                             │
    │                                                                        │
    │               ┌─────────────────────────────────────┐                  │
    │               │ one_arm_high AND standing_upright   │                  │
    │               │ AND NOT crouched?                   │                  │
    │               └───────────────┬─────────────────────┘                  │
    │                              │                                         │
    │                       Yes ───┼─── No                                   │
    │                        │           │                                   │
    │                        ▼           ▼                                   │
    │                  ┌──────────┐  ┌─────────────────────────┐             │
    │                  │  SERVE   │  │  crouched AND           │             │
    │                  │ (0.7)    │  │  hands_together?        │             │
    │                  └──────────┘  └───────────┬─────────────┘             │
    │                                           │                            │
    │                                    Yes ───┼─── No                      │
    │                                     │           │                      │
    │                                     ▼           ▼                      │
    │                        ┌─────────────────────┐  (more checks...)       │
    │                        │ deep_crouch (<100°)?│                         │
    │                        └──────────┬──────────┘                         │
    │                                  │                                     │
    │                           Yes ───┼─── No                               │
    │                            │           │                               │
    │                            ▼           ▼                               │
    │                      ┌──────────┐  ┌──────────┐                        │
    │                      │   DIG    │  │   PASS   │                        │
    │                      │ (0.8)    │  │ (0.7)    │                        │
    │                      └──────────┘  └──────────┘                        │
    │                                                                        │
    │   Default cases:                                                       │
    │   • crouched without hands together → READY                            │
    │   • arms raised (not above head) + symmetric → SET                     │
    │   • standing, not moving → IDLE                                        │
    │                                                                        │
    └────────────────────────────────────────────────────────────────────────┘
                │
                ▼
    ┌────────────────────────────────────────────────────────────────────────┐
    │                    TEMPORAL SMOOTHING                                  │
    │                                                                        │
    │   Maintain history of last 5 frames per track_id                       │
    │                                                                        │
    │   history[track_id] = [IDLE, SERVE, SERVE, SERVE, SERVE]               │
    │                                                                        │
    │   Use most common action if it appears >= 2 times:                     │
    │   Counter(history).most_common(1) → SERVE                              │
    │                                                                        │
    │   This prevents flickering between actions                             │
    │                                                                        │
    └────────────────────────────────────────────────────────────────────────┘
                │
                ▼
    ┌──────────────────────────┐
    │  Return ActionResult     │
    │                          │
    │  ActionResult:           │
    │  • track_id: 3           │
    │  • action: SERVE         │
    │  • confidence: 0.75      │
    │  • features: PoseFeatures│
    │  • frame_index: 150      │
    │  • secondary: SPIKE      │
    └──────────────────────────┘


Action Type Mapping (Classifier → Common):
────────────────────────────────────────────────────────────────────────────────
    Classifier        →    Common ActionType
    ─────────────────────────────────────────
    SERVE             →    SERVE
    SET               →    SET
    SPIKE             →    SPIKE
    BLOCK             →    BLOCK
    DIG               →    DIG
    PASS              →    RECEIVE
    IDLE              →    IDLE
    READY             →    IDLE
    JUMP              →    MOVING
    REACH             →    MOVING
    UNKNOWN           →    NO_CALL


3.6 SEGMENT EXTRACTION
--------------------------------------------------------------------------------

File: segments/extractor.py

┌─────────────────────────────────────────────────────────────────────────────┐
│                       SEGMENT EXTRACTION WORKFLOW                           │
└─────────────────────────────────────────────────────────────────────────────┘

    Input:  Stream of ActionResult per frame
    Output: List[ActionSegment] - temporal action segments

    The SegmentExtractor maintains state across frames and detects when
    actions start and end:

    ┌────────────────────────────────────────────────────────────────────────┐
    │                    INTERNAL STATE                                      │
    │                                                                        │
    │   _active: Dict[track_id, ActiveSegment]                               │
    │   ┌────────────────────────────────────────────────────────────────┐  │
    │   │  ActiveSegment:                                                │  │
    │   │  • track_id: 3                                                 │  │
    │   │  • action: SERVE                                               │  │
    │   │  • start_frame: 100                                            │  │
    │   │  • start_time: 3.33                                            │  │
    │   │  • confidences: [0.75, 0.78, 0.80, 0.77]                       │  │
    │   │  • frame_count: 4                                              │  │
    │   └────────────────────────────────────────────────────────────────┘  │
    │                                                                        │
    │   _segments: List[ActionSegment]  (completed segments)                 │
    │   _last_frame: Dict[track_id, frame_index]                             │
    │   _last_action: Dict[track_id, ActionType]                             │
    │                                                                        │
    └────────────────────────────────────────────────────────────────────────┘

    For each frame's ActionResult:

    ┌──────────────────────────┐
    │   ActionResult           │
    │   • track_id: 3          │
    │   • action: SERVE        │
    │   • confidence: 0.75     │
    └───────────┬──────────────┘
                │
                ▼
    ┌─────────────────────────────────────────────────┐
    │  Is there an active segment for this track_id?  │
    └───────────────────────┬─────────────────────────┘
                           │
                    Yes ───┼─── No
                     │     │     │
                     ▼           ▼
    ┌─────────────────────┐  ┌─────────────────────────┐
    │ Same action as      │  │ Start new segment       │
    │ active segment?     │  │                         │
    └──────────┬──────────┘  │ _active[track_id] =     │
              │              │   ActiveSegment(        │
       Yes ───┼─── No        │     track_id,           │
        │     │     │        │     action,             │
        ▼           ▼        │     frame_index,        │
    ┌─────────┐  ┌─────────┐ │     timestamp,          │
    │Continue │  │Close    │ │     [confidence])       │
    │ segment │  │ current │ └─────────────────────────┘
    │         │  │ & start │
    │ Append  │  │ new     │
    │ conf to │  │         │
    │ history │  │         │
    │ frame++ │  │         │
    └─────────┘  └─────────┘


    When closing a segment:

    ┌──────────────────────────────────────────────────────────────────────┐
    │                    CLOSE SEGMENT                                     │
    │                                                                      │
    │   1. Check minimum length:                                           │
    │      if frame_count < 5: discard (too short)                         │
    │                                                                      │
    │   2. Skip boring actions:                                            │
    │      if action in [IDLE, UNKNOWN]: discard                           │
    │                                                                      │
    │   3. Map to common types:                                            │
    │      Classifier ActionType → Common ActionType                       │
    │      (e.g., PASS → RECEIVE)                                          │
    │                                                                      │
    │   4. Calculate quality:                                              │
    │      avg_conf = mean(confidences)                                    │
    │      if avg_conf >= 0.7: GOOD                                        │
    │      elif avg_conf >= 0.5: UNCERTAIN                                 │
    │      else: UNRELIABLE                                                │
    │                                                                      │
    │   5. Create ActionSegment:                                           │
    │      • segment_id: uuid                                              │
    │      • player_id: "P3"                                               │
    │      • track_id: 3                                                   │
    │      • action: SERVE                                                 │
    │      • coarse_action: IN_PLAY                                        │
    │      • start_time: 3.33                                              │
    │      • end_time: 4.50                                                │
    │      • duration: 1.17                                                │
    │      • quality: GOOD                                                 │
    │      • avg_confidence: 0.77                                          │
    │      • frame_count: 35                                               │
    │      • start_frame: 100                                              │
    │      • end_frame: 135                                                │
    │                                                                      │
    │   6. Add to _segments list                                           │
    │                                                                      │
    └──────────────────────────────────────────────────────────────────────┘


    Finalization (after all frames processed):

    ┌──────────────────────────────────────────────────────────────────────┐
    │                    FINALIZE                                          │
    │                                                                      │
    │   1. Close all remaining active segments                             │
    │                                                                      │
    │   2. Merge consecutive same-action segments:                         │
    │      ┌────────────────────────────────────────────────────────────┐ │
    │      │  Before:                                                   │ │
    │      │  [SERVE 0-1s] [gap] [SERVE 1.1-2s] [gap] [SERVE 2.2-3s]   │ │
    │      │                                                            │ │
    │      │  After (if gaps <= 3 frames):                              │ │
    │      │  [SERVE 0-3s]                                              │ │
    │      └────────────────────────────────────────────────────────────┘ │
    │                                                                      │
    │   3. Sort by (start_time, track_id)                                  │
    │                                                                      │
    │   4. Return List[ActionSegment]                                      │
    │                                                                      │
    └──────────────────────────────────────────────────────────────────────┘


3.7 POST-PROCESSING
--------------------------------------------------------------------------------

File: segments/track_merger.py

┌─────────────────────────────────────────────────────────────────────────────┐
│                      POST-PROCESSING WORKFLOW                               │
└─────────────────────────────────────────────────────────────────────────────┘

    After segment extraction, we often have too many player IDs due to
    tracking fragmentation. Post-processing consolidates these.

    Problem:
    ┌────────────────────────────────────────────────────────────────────────┐
    │   Time:    0s -------- 30s -------- 60s -------- 90s                   │
    │                                                                        │
    │   P2:      [=====serves=====]                                          │
    │   P156:                       [====serves====]                         │
    │   P247:                                        [====serves====]        │
    │   P309:         [coach]                                                │
    │                                                                        │
    │   These are likely all the SAME player (just lost tracking)            │
    └────────────────────────────────────────────────────────────────────────┘

    Solution: Track Merging

    Step 1: Find Track Transitions
    ┌────────────────────────────────────────────────────────────────────────┐
    │   For each pair of tracks:                                             │
    │   • Check if they overlap in time (different players)                  │
    │   • Check if one ends and another begins within max_gap (2 seconds)    │
    │   • If sequential (not overlapping), they're candidates to merge       │
    │                                                                        │
    │   P2 ends at 30s, P156 starts at 31s → merge candidates                │
    │   P156 ends at 60s, P247 starts at 61s → merge candidates              │
    └────────────────────────────────────────────────────────────────────────┘

    Step 2: Build Track Clusters (Union-Find)
    ┌────────────────────────────────────────────────────────────────────────┐
    │   Merge pairs: [(P2, P156), (P156, P247)]                              │
    │                                                                        │
    │   Union-Find:                                                          │
    │   • union(P2, P156) → P2 is canonical                                  │
    │   • union(P156, P247) → P2 is still canonical                          │
    │                                                                        │
    │   Result: P2, P156, P247 all map to P2                                 │
    │          P309 stays as P309                                            │
    └────────────────────────────────────────────────────────────────────────┘

    Step 3: Activity-Based Merging (if max_players set)
    ┌────────────────────────────────────────────────────────────────────────┐
    │   If we still have > max_players (e.g., 2):                            │
    │                                                                        │
    │   1. Group by serve count:                                             │
    │      • main_players = tracks with serves > 0                           │
    │      • others = tracks with no serves                                  │
    │                                                                        │
    │   2. Merge all main_players into one (most active)                     │
    │   3. Merge all others into one "other" player                          │
    │                                                                        │
    │   Result: 2 players (main player + coach/other)                        │
    └────────────────────────────────────────────────────────────────────────┘

    Step 4: Update Segments
    ┌────────────────────────────────────────────────────────────────────────┐
    │   For each segment:                                                    │
    │   • Look up canonical ID from track_to_canonical mapping               │
    │   • Update player_id = f"P{canonical_id}"                              │
    │   • Update track_id = canonical_id                                     │
    │                                                                        │
    │   Before: segments with P2, P156, P247, P309                           │
    │   After:  segments with P2, P309 only                                  │
    └────────────────────────────────────────────────────────────────────────┘


3.8 EXPORT & ANALYTICS
--------------------------------------------------------------------------------

Files: pipeline/pipeline.py:559-604, analytics/stats.py, visualization/report.py

┌─────────────────────────────────────────────────────────────────────────────┐
│                       EXPORT & ANALYTICS WORKFLOW                           │
└─────────────────────────────────────────────────────────────────────────────┘

    After all segments are processed and merged:

    ┌──────────────────────────────────────────────────────────────────────┐
    │                    COMPUTE STATISTICS                                │
    │                                                                      │
    │   VideoStats:                                                        │
    │   • duration: 95.0 seconds                                           │
    │   • player_count: 2                                                  │
    │   • segment_count: 184                                               │
    │   • actions_per_minute: 116.2                                        │
    │                                                                      │
    │   PlayerStats (per player):                                          │
    │   ┌────────────────────────────────────────────────────────────────┐ │
    │   │  "P2" (Rithika):                                               │ │
    │   │  • segment_count: 182                                          │ │
    │   │  • total_time: 161.78 seconds                                  │ │
    │   │  • active_actions: 29 (serve, set, spike, block, dig)          │ │
    │   │  • avg_confidence: 0.673                                       │ │
    │   │  • action_counts:                                              │ │
    │   │    - serve: 28                                                 │ │
    │   │    - set: 0                                                    │ │
    │   │    - spike: 0                                                  │ │
    │   │    - block: 0                                                  │ │
    │   │    - dig: 1                                                    │ │
    │   │    - receive: 139 (excluded from active count)                 │ │
    │   │    - moving: 14                                                │ │
    │   └────────────────────────────────────────────────────────────────┘ │
    │                                                                      │
    └──────────────────────────────────────────────────────────────────────┘
                │
                ▼
    ┌──────────────────────────────────────────────────────────────────────┐
    │                    EXPORT FILES                                      │
    │                                                                      │
    │   segments.jsonl (one JSON object per line):                         │
    │   ────────────────────────────────────────────────────────────────   │
    │   {"segment_id":"abc123","player_id":"P2","action":"serve",...}      │
    │   {"segment_id":"def456","player_id":"P2","action":"serve",...}      │
    │   ...                                                                │
    │                                                                      │
    │   summary.json:                                                      │
    │   ────────────────────────────────────────────────────────────────   │
    │   {                                                                  │
    │     "video_path": "Rithika_Training.MOV",                            │
    │     "duration_sec": 95.0,                                            │
    │     "total_segments": 184,                                           │
    │     "player_count": 2,                                               │
    │     "action_distribution": {"serve": 28, "dig": 1, ...}              │
    │   }                                                                  │
    │                                                                      │
    │   player_stats.json:                                                 │
    │   ────────────────────────────────────────────────────────────────   │
    │   {                                                                  │
    │     "P2": {                                                          │
    │       "segment_count": 182,                                          │
    │       "total_time_sec": 161.78,                                      │
    │       "active_actions": 29,                                          │
    │       "action_counts": {"serve": 28, "dig": 1, ...}                  │
    │     },                                                               │
    │     "P309": {...}                                                    │
    │   }                                                                  │
    │                                                                      │
    │   report.html (optional):                                            │
    │   ────────────────────────────────────────────────────────────────   │
    │   Interactive HTML with:                                             │
    │   • Action distribution pie chart                                    │
    │   • Timeline visualization                                           │
    │   • Per-player statistics                                            │
    │   • Video player integration                                         │
    │                                                                      │
    └──────────────────────────────────────────────────────────────────────┘


================================================================================
                    4. DEEP TASK BREAKDOWNS
================================================================================

4.1 DETECTION DEEP DIVE
--------------------------------------------------------------------------------

File: detection_tracking/detector.py

YOLO v8 Configuration:
    • Model: yolov8n.pt (nano - fastest, ~3.2M parameters)
    • Input: BGR frame, any resolution
    • Output: Boxes, scores, class IDs
    • Confidence threshold: 0.4

Detection Filtering:

    ┌────────────────────────────────────────────────────────────────────────┐
    │  filter_detections_by_size(detections, frame_size)                     │
    │                                                                        │
    │  Parameters:                                                           │
    │  • min_area: 1000 pixels²                                              │
    │  • max_area: 50% of frame area                                         │
    │  • min_aspect_ratio: 0.2 (height/width)                                │
    │  • max_aspect_ratio: 2.0                                               │
    │                                                                        │
    │  Purpose: Remove false positives (too small = noise, too large = bad)  │
    └────────────────────────────────────────────────────────────────────────┘

    ┌────────────────────────────────────────────────────────────────────────┐
    │  filter_detections_by_position(detections, frame_size)                 │
    │                                                                        │
    │  Parameters:                                                           │
    │  • edge_margin: 5% of frame dimensions                                 │
    │                                                                        │
    │  Removes detections where bbox center is within edge margin            │
    │  Purpose: Remove partial detections at frame edges                     │
    └────────────────────────────────────────────────────────────────────────┘


4.2 TRACKING DEEP DIVE (ByteTrack)
--------------------------------------------------------------------------------

File: detection_tracking/bytetrack.py

ByteTrack is a multi-object tracking algorithm that handles occlusion well
by using both high-confidence and low-confidence detections.

Key Components:

    ┌────────────────────────────────────────────────────────────────────────┐
    │  Track State Machine                                                   │
    │                                                                        │
    │   ┌─────────────────┐                                                  │
    │   │   TENTATIVE     │ ──── hits >= min_hits ────▶ ┌───────────────┐   │
    │   │  (new track)    │                             │   CONFIRMED   │   │
    │   └────────┬────────┘                             │  (active)     │   │
    │            │                                      └───────┬───────┘   │
    │            │                                              │            │
    │            │ not matched                                  │ not matched│
    │            │ for 1 frame                                  │ for N frames│
    │            ▼                                              ▼            │
    │   ┌─────────────────┐                             ┌───────────────┐   │
    │   │    DELETED      │ ◀──── not matched ──────── │     LOST      │   │
    │   │  (removed)      │       for track_buffer     │  (searching)  │   │
    │   └─────────────────┘       frames               └───────────────┘   │
    │                                                                        │
    └────────────────────────────────────────────────────────────────────────┘

    ┌────────────────────────────────────────────────────────────────────────┐
    │  Matching Algorithm                                                    │
    │                                                                        │
    │  1. Compute IoU (Intersection over Union) matrix:                      │
    │                                                                        │
    │              Det1    Det2    Det3                                      │
    │     Track1  [0.85]  [0.10]  [0.05]                                     │
    │     Track2  [0.12]  [0.78]  [0.15]                                     │
    │     Track3  [0.05]  [0.20]  [0.82]                                     │
    │                                                                        │
    │  2. Hungarian algorithm finds optimal assignment:                      │
    │     Track1 ↔ Det1 (IoU=0.85)                                           │
    │     Track2 ↔ Det2 (IoU=0.78)                                           │
    │     Track3 ↔ Det3 (IoU=0.82)                                           │
    │                                                                        │
    │  3. Filter by threshold (match_thresh=0.3):                            │
    │     All matches above 0.3 → confirmed                                  │
    │                                                                        │
    └────────────────────────────────────────────────────────────────────────┘

    ┌────────────────────────────────────────────────────────────────────────┐
    │  Re-ID (Re-Identification) using Appearance                            │
    │                                                                        │
    │  For each detection/track, extract color histogram:                    │
    │                                                                        │
    │  1. Crop bbox region from frame                                        │
    │  2. Convert to HSV color space                                         │
    │  3. Compute histogram (H: 50 bins, S: 50 bins)                         │
    │  4. Normalize histogram                                                │
    │                                                                        │
    │  Similarity = histogram correlation (cv2.compareHist)                  │
    │                                                                        │
    │  When track is lost for many frames:                                   │
    │  • Compare new detection histogram with stored track histogram         │
    │  • If similarity >= 0.6, re-identify as same track                     │
    │                                                                        │
    │  This helps when player leaves and returns to frame                    │
    └────────────────────────────────────────────────────────────────────────┘


4.3 POSE ESTIMATION DEEP DIVE (MediaPipe)
--------------------------------------------------------------------------------

File: pose/estimator.py

MediaPipe Pose (BlazePose) Architecture:

    ┌────────────────────────────────────────────────────────────────────────┐
    │  Model Complexity Options                                              │
    │                                                                        │
    │  complexity=0 (Lite):                                                  │
    │  • Fastest, lower accuracy                                             │
    │  • Good for real-time on mobile                                        │
    │                                                                        │
    │  complexity=1 (Full) [DEFAULT]:                                        │
    │  • Balanced speed/accuracy                                             │
    │  • Good for most applications                                          │
    │                                                                        │
    │  complexity=2 (Heavy):                                                 │
    │  • Slowest, highest accuracy                                           │
    │  • Good for offline processing                                         │
    └────────────────────────────────────────────────────────────────────────┘

    ┌────────────────────────────────────────────────────────────────────────┐
    │  33 Keypoints Layout                                                   │
    │                                                                        │
    │                        (0) NOSE                                        │
    │                     (1)   (4)                                          │
    │                 (2) LEFT   RIGHT (5)                                   │
    │              (3) EYE  ◉   ◉  EYE (6)                                   │
    │                  (7)  ┌───┐  (8)                                       │
    │                 EAR   │ . │   EAR                                      │
    │                      (9) (10) MOUTH                                    │
    │                                                                        │
    │             (11)────────────────(12)                                   │
    │         SHOULDER              SHOULDER                                 │
    │              │                    │                                    │
    │            (13)                 (14)                                   │
    │           ELBOW                ELBOW                                   │
    │              │                    │                                    │
    │            (15)                 (16)                                   │
    │           WRIST                WRIST                                   │
    │           /│\                   /│\                                    │
    │       (17)(19)(21)         (18)(20)(22)                                │
    │                                                                        │
    │             (23)────────────────(24)                                   │
    │            HIP                  HIP                                    │
    │              │                    │                                    │
    │            (25)                 (26)                                   │
    │           KNEE                 KNEE                                    │
    │              │                    │                                    │
    │            (27)                 (28)                                   │
    │           ANKLE                ANKLE                                   │
    │            /                      \                                    │
    │         (29)                     (30)                                  │
    │         HEEL                     HEEL                                  │
    │            \                      /                                    │
    │           (31)                 (32)                                    │
    │         FOOT INDEX           FOOT INDEX                                │
    │                                                                        │
    └────────────────────────────────────────────────────────────────────────┘

Joint Angle Calculation:

    ┌────────────────────────────────────────────────────────────────────────┐
    │  get_joint_angle(joint1, joint2, joint3)                               │
    │                                                                        │
    │  Calculates angle at joint2 formed by joint1→joint2→joint3             │
    │                                                                        │
    │          joint1                                                        │
    │             \                                                          │
    │              \  v1                                                     │
    │               \                                                        │
    │              joint2 ────────── angle θ                                 │
    │               /                                                        │
    │              /  v2                                                     │
    │             /                                                          │
    │          joint3                                                        │
    │                                                                        │
    │  Formula:                                                              │
    │  v1 = (joint1.x - joint2.x, joint1.y - joint2.y)                       │
    │  v2 = (joint3.x - joint2.x, joint3.y - joint2.y)                       │
    │  cos(θ) = (v1 · v2) / (|v1| * |v2|)                                    │
    │  θ = arccos(cos(θ)) in degrees                                         │
    │                                                                        │
    │  Examples:                                                             │
    │  • Elbow angle: shoulder → elbow → wrist                               │
    │  • Knee angle: hip → knee → ankle                                      │
    └────────────────────────────────────────────────────────────────────────┘


4.4 ACTION CLASSIFICATION DEEP DIVE
--------------------------------------------------------------------------------

File: actions/classifier.py

Thresholds (configurable in __init__):

    ┌────────────────────────────────────────────────────────────────────────┐
    │  Threshold                │ Default │ Purpose                          │
    │  ─────────────────────────┼─────────┼────────────────────────────────  │
    │  high_hand_threshold      │  50 px  │ Hands "raised" above shoulders   │
    │  very_high_hand_threshold │ 100 px  │ Hands very high (spike/serve)    │
    │  crouch_threshold         │ 140°    │ Knee angle = crouching           │
    │  deep_crouch_threshold    │ 100°    │ Deep squat (dig)                 │
    │  bent_elbow_threshold     │ 120°    │ Arm is bent                      │
    │  hands_together_threshold │ 100 px  │ Platform position                │
    └────────────────────────────────────────────────────────────────────────┘

Complete Decision Tree:

    ┌────────────────────────────────────────────────────────────────────────┐
    │                                                                        │
    │  confidence < 0.3 ─────────────────────────────────────▶ UNKNOWN       │
    │       │                                                                │
    │       ▼ (confidence >= 0.3)                                            │
    │                                                                        │
    │  hands_above_head AND max_hand_height > 100px?                         │
    │       │                                                                │
    │  Yes ─┼─ No ──────────────────────────────────────────────────────┐    │
    │       │                                                           │    │
    │       ▼                                                           │    │
    │  arms_symmetry > 0.7?                                             │    │
    │       │                                                           │    │
    │  Yes ─┼─ No                                                       │    │
    │   │   │   │                                                       │    │
    │   ▼       ▼                                                       │    │
    │ BLOCK  standing_upright?                                          │    │
    │ (0.8)     │                                                       │    │
    │      Yes ─┼─ No                                                   │    │
    │       │   │   │                                                   │    │
    │       ▼       ▼                                                   │    │
    │    SERVE    SPIKE                                                 │    │
    │    (0.75)   (0.7)                                                 │    │
    │                                                                   │    │
    │  ◀────────────────────────────────────────────────────────────────┘    │
    │       │ (hands not very high)                                          │
    │       ▼                                                                │
    │  one_arm_high AND standing_upright AND NOT crouched?                   │
    │       │                                                                │
    │  Yes ─┼─ No ──────────────────────────────────────────────────────┐    │
    │       │                                                           │    │
    │       ▼                                                           │    │
    │  arm_height_diff > 30?                                            │    │
    │       │                                                           │    │
    │  Yes ─┼─ No                                                       │    │
    │   │   │   │                                                       │    │
    │   ▼       ▼                                                       │    │
    │ SERVE    SET                                                      │    │
    │ (0.7)   (0.6)                                                     │    │
    │                                                                   │    │
    │  ◀────────────────────────────────────────────────────────────────┘    │
    │       │ (not one arm high + standing)                                  │
    │       ▼                                                                │
    │  crouched AND hands_together?                                          │
    │       │                                                                │
    │  Yes ─┼─ No ──────────────────────────────────────────────────────┐    │
    │       │                                                           │    │
    │       ▼                                                           │    │
    │  avg_knee_angle < 100° (deep crouch)?                             │    │
    │       │                                                           │    │
    │  Yes ─┼─ No                                                       │    │
    │   │   │   │                                                       │    │
    │   ▼       ▼                                                       │    │
    │  DIG    PASS                                                      │    │
    │ (0.8)  (0.7)                                                      │    │
    │                                                                   │    │
    │  ◀────────────────────────────────────────────────────────────────┘    │
    │       │ (not crouched with hands together)                             │
    │       ▼                                                                │
    │  crouched?                                                             │
    │       │                                                                │
    │  Yes ─┼─ No ──────────────────────────────────────────────────────┐    │
    │       │                                                           │    │
    │       ▼                                                           │    │
    │  arms_raised?                                                     │    │
    │       │                                                           │    │
    │  Yes ─┼─ No                                                       │    │
    │   │   │   │                                                       │    │
    │   ▼       ▼                                                       │    │
    │ REACH   READY                                                     │    │
    │ (0.6)   (0.6)                                                     │    │
    │                                                                   │    │
    │  ◀────────────────────────────────────────────────────────────────┘    │
    │       │ (not crouched)                                                 │
    │       ▼                                                                │
    │  arms_raised AND NOT hands_above_head?                                 │
    │       │                                                                │
    │  Yes ─┼─ No ──────────────────────────────────────────────────────┐    │
    │       │                                                           │    │
    │       ▼                                                           │    │
    │  one_arm_high AND standing AND arm_diff > 40?                     │    │
    │       │                                                           │    │
    │  Yes ─┼─ No                                                       │    │
    │   │   │   │                                                       │    │
    │   ▼       ▼                                                       │    │
    │ SERVE  arms_symmetry > 0.6?                                       │    │
    │ (0.65)    │                                                       │    │
    │      Yes ─┼─ No                                                   │    │
    │       │   │   │                                                   │    │
    │       ▼       ▼                                                   │    │
    │     SET     REACH                                                 │    │
    │    (0.6)    (0.5)                                                 │    │
    │                                                                   │    │
    │  ◀────────────────────────────────────────────────────────────────┘    │
    │       │ (arms not raised)                                              │
    │       ▼                                                                │
    │  hands_together AND hands below shoulders?                             │
    │       │                                                                │
    │  Yes ─┼─ No                                                            │
    │   │   │   │                                                            │
    │   ▼       ▼                                                            │
    │ PASS   avg_knee_angle > 160?                                           │
    │ (0.7)     │                                                            │
    │      Yes ─┼─ No                                                        │
    │       │   │   │                                                        │
    │       ▼       ▼                                                        │
    │     IDLE    READY                                                      │
    │    (0.5)    (0.5)                                                      │
    │                                                                        │
    └────────────────────────────────────────────────────────────────────────┘


4.5 SEGMENT EXTRACTION DEEP DIVE
--------------------------------------------------------------------------------

File: segments/extractor.py

Configuration:

    ┌────────────────────────────────────────────────────────────────────────┐
    │  Parameter           │ Default │ Purpose                               │
    │  ────────────────────┼─────────┼─────────────────────────────────────  │
    │  fps                 │  30.0   │ Video frame rate                      │
    │  min_segment_frames  │    5    │ Minimum frames for valid segment      │
    │                      │         │ (~0.17s at 30fps)                     │
    │  max_gap_frames      │    3    │ Max gap to merge same action          │
    │                      │         │ (~0.1s at 30fps)                      │
    │  merge_similar       │  True   │ Merge consecutive same actions        │
    └────────────────────────────────────────────────────────────────────────┘

Quality Assignment:

    ┌────────────────────────────────────────────────────────────────────────┐
    │  Average Confidence   │  Quality                                       │
    │  ─────────────────────┼──────────────────────────────────────────────  │
    │  >= 0.70              │  GOOD                                          │
    │  0.50 - 0.69          │  UNCERTAIN                                     │
    │  < 0.50               │  UNRELIABLE                                    │
    └────────────────────────────────────────────────────────────────────────┘

Coarse Action Mapping:

    ┌────────────────────────────────────────────────────────────────────────┐
    │  ActionType    │  CoarseAction                                         │
    │  ──────────────┼────────────────────────────────────────────────────── │
    │  SERVE         │  IN_PLAY                                              │
    │  SET           │  IN_PLAY                                              │
    │  SPIKE         │  IN_PLAY                                              │
    │  BLOCK         │  IN_PLAY                                              │
    │  DIG           │  IN_PLAY                                              │
    │  RECEIVE       │  IN_PLAY                                              │
    │  MOVING        │  MOVING                                               │
    │  IDLE          │  IDLE                                                 │
    │  CELEBRATE     │  IDLE                                                 │
    │  NO_CALL       │  UNKNOWN                                              │
    └────────────────────────────────────────────────────────────────────────┘


4.6 TRACK MERGING DEEP DIVE
--------------------------------------------------------------------------------

File: segments/track_merger.py

Union-Find Algorithm:

    ┌────────────────────────────────────────────────────────────────────────┐
    │  Union-Find (Disjoint Set Union)                                       │
    │                                                                        │
    │  Data Structure:                                                       │
    │  parent = {track_id: parent_track_id}                                  │
    │                                                                        │
    │  Initially: each track is its own parent                               │
    │  parent = {2: 2, 156: 156, 247: 247, 309: 309}                         │
    │                                                                        │
    │  find(x): Returns root of x's tree (with path compression)             │
    │  ─────────────────────────────────────────────────────────────────     │
    │  def find(x):                                                          │
    │      if parent[x] != x:                                                │
    │          parent[x] = find(parent[x])  # Path compression               │
    │      return parent[x]                                                  │
    │                                                                        │
    │  union(x, y): Merge x and y's trees (smaller ID becomes root)          │
    │  ─────────────────────────────────────────────────────────────────     │
    │  def union(x, y):                                                      │
    │      px, py = find(x), find(y)                                         │
    │      if px != py:                                                      │
    │          if px < py:                                                   │
    │              parent[py] = px                                           │
    │          else:                                                         │
    │              parent[px] = py                                           │
    │                                                                        │
    │  Example:                                                              │
    │  union(2, 156) → parent = {2: 2, 156: 2, 247: 247, 309: 309}           │
    │  union(156, 247) → parent = {2: 2, 156: 2, 247: 2, 309: 309}           │
    │                                                                        │
    │  Final mapping: {2: 2, 156: 2, 247: 2, 309: 309}                       │
    └────────────────────────────────────────────────────────────────────────┘


================================================================================
                    5. DATA TYPES REFERENCE
================================================================================

5.1 CORE ENUMS
--------------------------------------------------------------------------------

File: common/data_types.py

    ┌────────────────────────────────────────────────────────────────────────┐
    │  ActionType (Fine-grained)          │  CoarseAction (Fallback)         │
    │  ────────────────────────────────── │ ─────────────────────────────── │
    │  SERVE    "serve"                   │  IN_PLAY         "in_play"       │
    │  SET      "set"                     │  MOVING          "moving"        │
    │  SPIKE    "spike"                   │  READY_POSITION  "ready_position"│
    │  BLOCK    "block"                   │  IDLE            "idle"          │
    │  DIG      "dig"                     │  UNKNOWN         "unknown"       │
    │  RECEIVE  "receive"                 │                                  │
    │  CELEBRATE "celebrate"              │                                  │
    │  IDLE     "idle"                    │                                  │
    │  MOVING   "moving"                  │                                  │
    │  NO_CALL  "no_call"                 │                                  │
    └────────────────────────────────────────────────────────────────────────┘

    ┌────────────────────────────────────────────────────────────────────────┐
    │  SegmentQuality              │  VisionQuality                          │
    │  ─────────────────────────── │ ─────────────────────────────────────  │
    │  GOOD        "good"          │  GOOD        "good"                     │
    │  UNCERTAIN   "uncertain"     │  UNCERTAIN   "uncertain"                │
    │  UNRELIABLE  "unreliable"    │  UNRELIABLE  "unreliable"               │
    └────────────────────────────────────────────────────────────────────────┘

    ┌────────────────────────────────────────────────────────────────────────┐
    │  Visibility                  │  ActionResult                           │
    │  ─────────────────────────── │ ─────────────────────────────────────  │
    │  FULL     "full"    (>80%)   │  SUCCESS   "success"                    │
    │  PARTIAL  "partial" (50-80%) │  IN_PLAY   "in_play"                    │
    │  POOR     "poor"    (<50%)   │  OUT       "out"                        │
    │                              │  NET       "net"                        │
    │                              │  FAULT     "fault"                      │
    │                              │  BLOCKED   "blocked"                    │
    │                              │  UNKNOWN   "unknown"                    │
    └────────────────────────────────────────────────────────────────────────┘


5.2 DATA CLASSES
--------------------------------------------------------------------------------

    ┌────────────────────────────────────────────────────────────────────────┐
    │  BoundingBox                                                           │
    │  ──────────────────────────────────────────────────────────────────── │
    │  x1: int          Top-left x coordinate                                │
    │  y1: int          Top-left y coordinate                                │
    │  x2: int          Bottom-right x coordinate                            │
    │  y2: int          Bottom-right y coordinate                            │
    │  Properties:                                                           │
    │  • width: x2 - x1                                                      │
    │  • height: y2 - y1                                                     │
    │  • area: width * height                                                │
    │  • center: ((x1+x2)/2, (y1+y2)/2)                                      │
    └────────────────────────────────────────────────────────────────────────┘

    ┌────────────────────────────────────────────────────────────────────────┐
    │  Detection                                                             │
    │  ──────────────────────────────────────────────────────────────────── │
    │  bbox: BoundingBox     Bounding box coordinates                        │
    │  confidence: float     Detection confidence (0-1)                      │
    │  class_id: int = 0     COCO class ID (0 = person)                      │
    │  class_name: str       Human-readable class name                       │
    └────────────────────────────────────────────────────────────────────────┘

    ┌────────────────────────────────────────────────────────────────────────┐
    │  TrackedPerson                                                         │
    │  ──────────────────────────────────────────────────────────────────── │
    │  track_id: int             Persistent ID across frames                 │
    │  bbox: BoundingBox         Current bounding box                        │
    │  det_conf: float           Detection confidence this frame             │
    │  frame_index: int          Current frame number                        │
    │  timestamp: float          Current timestamp (seconds)                 │
    │  track_age: int            Frames since first detection                │
    │  frames_since_update: int  Frames since last match                     │
    │  avg_confidence: float     Running average confidence                  │
    │  is_confirmed: bool        Track confirmed (age >= threshold)          │
    └────────────────────────────────────────────────────────────────────────┘

    ┌────────────────────────────────────────────────────────────────────────┐
    │  ActionSegment                                                         │
    │  ──────────────────────────────────────────────────────────────────── │
    │  segment_id: str           Unique identifier (UUID)                    │
    │  player_id: str            Player identifier ("P3")                    │
    │  track_id: int             Associated track ID                         │
    │  action: ActionType        Fine-grained action type                    │
    │  coarse_action: CoarseAction  Fallback category                        │
    │  start_time: float         Start timestamp (seconds)                   │
    │  end_time: float           End timestamp (seconds)                     │
    │  duration: float           Duration (seconds)                          │
    │  quality: SegmentQuality   Quality assessment                          │
    │  avg_confidence: float     Average confidence during segment           │
    │  result: ActionResult      Action result (if applicable)               │
    │  court_x: Optional[float]  Court x position (0-1)                      │
    │  court_y: Optional[float]  Court y position (0-1)                      │
    │  frame_count: int          Number of frames                            │
    │  start_frame: int          Starting frame index                        │
    │  end_frame: int            Ending frame index                          │
    └────────────────────────────────────────────────────────────────────────┘


5.3 TYPE MAPPINGS
--------------------------------------------------------------------------------

Classifier ActionType → Common ActionType (pipeline.py:447-459):

    ┌────────────────────┬─────────────────────┐
    │  Classifier        │  Common             │
    ├────────────────────┼─────────────────────┤
    │  SERVE             │  SERVE              │
    │  SET               │  SET                │
    │  SPIKE             │  SPIKE              │
    │  BLOCK             │  BLOCK              │
    │  DIG               │  DIG                │
    │  PASS              │  RECEIVE            │
    │  IDLE              │  IDLE               │
    │  READY             │  IDLE               │
    │  JUMP              │  MOVING             │
    │  REACH             │  MOVING             │
    │  UNKNOWN           │  NO_CALL            │
    └────────────────────┴─────────────────────┘


================================================================================
                    6. CONFIGURATION REFERENCE
================================================================================

File: common/config.py

Default Configuration:

    ┌────────────────────────────────────────────────────────────────────────┐
    │  PipelineConfig                                                        │
    │                                                                        │
    │  detection:                                                            │
    │  ├── model_name: "yolov8n.pt"                                          │
    │  ├── confidence_threshold: 0.4                                         │
    │  └── device: "auto"                                                    │
    │                                                                        │
    │  tracking:                                                             │
    │  ├── max_players: 12                                                   │
    │  ├── track_buffer: 150 (frames, ~5 sec at 30fps)                       │
    │  ├── track_thresh: 0.3                                                 │
    │  └── match_thresh: 0.4                                                 │
    │                                                                        │
    │  pose:                                                                 │
    │  ├── model_complexity: 1 (0=lite, 1=full, 2=heavy)                     │
    │  ├── min_detection_confidence: 0.5                                     │
    │  └── min_tracking_confidence: 0.5                                      │
    │                                                                        │
    │  segment:                                                              │
    │  └── min_duration_sec: 0.17 (~5 frames)                                │
    │                                                                        │
    │  stabilization:                                                        │
    │  ├── smoothing_window: 30                                              │
    │  ├── border_crop: 0.1                                                  │
    │  └── max_features: 200                                                 │
    │                                                                        │
    └────────────────────────────────────────────────────────────────────────┘


================================================================================
                           END OF DOCUMENT
================================================================================

                    Generated for: Volleyball Analytics v1.0
                    Documentation created: December 2024

================================================================================
