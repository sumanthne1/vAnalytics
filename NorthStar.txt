================================================================================
VOLLEY MOMENTS: NORTH STAR VISION vs CURRENT ARCHITECTURE
Gap Analysis & Implementation Roadmap
================================================================================

Date: 2025-12-13
Current Architecture Version: Based on latest commit (3d17878)

================================================================================
EXECUTIVE SUMMARY
================================================================================

PRODUCT VISION: "Volley Moments" - A parent/coach-focused volleyball analytics
platform that transforms raw game footage into actionable insights, highlights,
and personalized feedback for youth volleyball players.

FEASIBILITY ASSESSMENT:
  - Core Video Processing: 70% READY
  - Player Analytics: 40% READY
  - Parent/Coach Features: 15% READY
  - Human-in-the-Loop: 0% READY

CRITICAL CHALLENGES:
  1. Action classification accuracy (currently rule-based, ~60-70% accuracy)
  2. Individual player identification (track merging issues)
  3. Court context & positioning accuracy
  4. Rotation/lineup tracking (NOT IMPLEMENTED)
  5. Momentum/psychological insights (NOT IMPLEMENTED)
  6. Human validation workflow (NOT IMPLEMENTED)

================================================================================
SECTION 1: PARENT VIEW FEATURES - FEASIBILITY ANALYSIS
================================================================================

Based on mockup images (Parent-1 to Parent-4), the parent view requires:

┌─────────────────────────────────────────────────────────────────────────────┐
│ 1.1 PLAYER PROFILE & SEASON HIGHLIGHTS (Parent-1.png)                      │
└─────────────────────────────────────────────────────────────────────────────┘

REQUIRED FEATURES:
  ✓ Player name/number/position identification
  ✓ Season-long statistics aggregation
  ✓ Personalized highlights ("Proud of", "Growing", "Next focus")
  ✓ Confidence metrics trending
  ✓ Serve accuracy percentage

CURRENT CAPABILITY:
  [PARTIAL - 30%]

  ✓ IMPLEMENTED:
    - Track ID assignment (volley_analytics/detection_tracking/tracker.py)
    - Basic action segmentation (volley_analytics/segments/extractor.py)
    - Serve/spike/block detection via pose (volley_analytics/actions/classifier.py)

  ✗ MISSING:
    - Jersey number recognition (OCR not implemented)
    - Player name database/mapping (no player registry)
    - Position assignment (no court zone analysis for roles)
    - Serve accuracy outcome detection (ball tracking NOT implemented)
    - Confidence/hustle metrics (subjective, requires HITL)
    - Trend analysis over multiple games (no multi-game database)
    - Natural language insight generation ("Great timing on this kill!")

ACCURACY CHALLENGES:
  • Track ID consistency: ByteTrack can lose/reassign IDs during:
    - Substitutions
    - Occlusions
    - Camera cuts
    - Players leaving/entering frame

  • Action classification confidence: ~60-70% for complex actions
    - SERVE: 70% accurate (distinguishes from spike reasonably well)
    - SPIKE: 65% accurate (confused with reach/jump sometimes)
    - BLOCK: 75% accurate (symmetric arm raising works well)
    - DIG: 60% accurate (often confused with ready position)
    - SET: 55% accurate (hands near face is ambiguous)

  • No outcome tracking: Cannot determine if serve was:
    - Ace
    - In play
    - Fault
    - Out

IMPLEMENTATION GAPS:
  1. Ball tracking module (NOT IMPLEMENTED)
     - Required for: serve outcome, spike success, reception quality
     - Complexity: HIGH (small object, motion blur, occlusion)
     - Estimated effort: 4-6 weeks

  2. Jersey number OCR
     - Required for: player identification
     - Complexity: MEDIUM (need number detection + OCR)
     - Estimated effort: 2-3 weeks

  3. Player database & identity persistence
     - Required for: cross-game tracking, season stats
     - Complexity: LOW (database schema + API)
     - Estimated effort: 1 week

  4. NLP insight generation
     - Required for: "Proud of 92% serves in + strong hustle"
     - Complexity: HIGH (requires context understanding + templates)
     - Estimated effort: 3-4 weeks

┌─────────────────────────────────────────────────────────────────────────────┐
│ 1.2 PERFORMANCE STATS & VIDEO CLIPS (Parent-2.png)                         │
└─────────────────────────────────────────────────────────────────────────────┘

REQUIRED FEATURES:
  ✓ Attack points (kills) counter
  ✓ Attack success percentage
  ✓ Serve in-play percentage
  ✓ Ace serves counter
  ✓ Defensive saves (digs) counter
  ✓ "Plays to Review" clips with video scrubbing
  ✓ Comparison to player's last 5 games

CURRENT CAPABILITY:
  [PARTIAL - 40%]

  ✓ IMPLEMENTED:
    - Action counting (stats.py:count_actions)
    - Segment extraction with timestamps (segments/extractor.py)
    - Video clip export (NOT WIRED to web interface)
    - Per-player statistics (stats.py:compute_player_stats)

  ✗ MISSING:
    - Attack success/failure outcome (ball trajectory NOT tracked)
    - Serve ace detection (requires ball + opponent position analysis)
    - "Plays to Review" clip auto-selection (heuristic NOT implemented)
    - Comparison logic across games (multi-game database missing)
    - Web video player integration
    - Video clip thumbnails/previews

ACCURACY CHALLENGES:
  • Counting accuracy depends on action classification
    - Spike count: includes both successful kills AND blocked spikes
    - Cannot distinguish: kill vs. error vs. blocked

  • No rally outcome tracking:
    - Did the spike score a point?
    - Was it dug by opponent?
    - Did it go out?

  • Defensive saves overcounting:
    - Ready position sometimes classified as dig
    - Platform passes can be counted as digs

IMPLEMENTATION GAPS:
  1. Rally outcome detection
     - Requires: ball tracking + scoreboard OCR OR manual annotation
     - Complexity: VERY HIGH
     - Estimated effort: 6-8 weeks (automated) OR 2 weeks (HITL)

  2. "Great plays" heuristic engine
     - Logic: high-confidence actions + rally outcome + context
     - Complexity: MEDIUM
     - Estimated effort: 2 weeks

  3. Multi-game database & comparison
     - Schema for games, players, seasons
     - Complexity: LOW
     - Estimated effort: 1 week

┌─────────────────────────────────────────────────────────────────────────────┐
│ 1.3 GAME MOMENTS & LEARNING OPPORTUNITIES (Parent-3.png)                   │
└─────────────────────────────────────────────────────────────────────────────┘

REQUIRED FEATURES:
  ✓ Categorized moment clips:
    - "Next Play" (learning opportunities)
    - "Learn" (correctable mistakes)
    - "Hustle Play" (effort moments)
  ✓ Coach-written explanations:
    - "Why this matters"
    - "Great execution under pressure builds confidence"
  ✓ Privacy controls (sharing links)

CURRENT CAPABILITY:
  [MINIMAL - 15%]

  ✓ IMPLEMENTED:
    - Segment extraction with quality scores
    - Video clip export capability (basic)

  ✗ MISSING:
    - Moment categorization logic (Next Play vs Learn vs Hustle)
    - Coach annotation interface (NO UI/workflow)
    - "Why this matters" text authoring
    - Sharing/privacy system
    - Clip embedding for web/mobile

ACCURACY CHALLENGES:
  • Cannot auto-detect "learning moments" without:
    - Error classification (what went wrong?)
    - Game situation context (was it set point? match point?)
    - Coach judgment (subjective evaluation)

  • "Hustle plays" detection:
    - Requires effort metrics: dive speed, scramble distance
    - Current pose estimation cannot reliably detect diving/scrambling
    - No proximity-to-ball tracking

IMPLEMENTATION GAPS:
  1. Moment categorization engine
     - REQUIRES: Human-in-the-loop for labeling training data
     - OR: Simple rule-based heuristics (e.g., blocked spike = "Learn")
     - Complexity: MEDIUM (rules) to HIGH (ML)
     - Estimated effort: 3-4 weeks

  2. Coach annotation workflow
     - Web interface for coaches to:
       - Review auto-detected moments
       - Add "Why this matters" text
       - Categorize (Next Play / Learn / Hustle)
       - Approve for parent sharing
     - Complexity: MEDIUM (full-stack feature)
     - Estimated effort: 4-5 weeks

  3. Privacy & sharing system
     - Link generation with expiry
     - Parent-only vs team-wide sharing
     - Complexity: MEDIUM
     - Estimated effort: 2-3 weeks

┌─────────────────────────────────────────────────────────────────────────────┐
│ 1.4 COACHING GUIDANCE & ACTIONABLE TIPS (Parent-4.png)                     │
└─────────────────────────────────────────────────────────────────────────────┘

REQUIRED FEATURES:
  ✓ "What to Work on Next" prioritized list:
    1. Serving accuracy - "keep up the great work"
    2. Hitting to corners - "try hitting to different zones"
    3. Reading defense - "focus on court vision"
  ✓ Data-driven rationale:
    - "92% serves in is well above average"
    - "10-minute drill: Practice 20 serves to different zones"
  ✓ Actionable next match goals:
    - "Try 5 corner swings next match"
  ✓ Parent tips:
    - "Frame it positively: What's your intent in serving so well?"

CURRENT CAPABILITY:
  [NONE - 0%]

  ✗ COMPLETELY MISSING:
    - No insight generation system
    - No drill recommendation database
    - No parent communication templates
    - No benchmark data (what is "above average"?)

ACCURACY CHALLENGES:
  • Requires domain expertise:
    - Volleyball coaching knowledge base
    - Age-appropriate drill database
    - Developmental milestones for different skill levels

  • Needs baseline data:
    - Average serve accuracy for 14U, 16U, 18U players
    - Positional benchmarks (OH vs MB vs S)

IMPLEMENTATION GAPS:
  1. Insight engine with coaching knowledge base
     - Template library: "92% serves is excellent for [age group]"
     - Drill database indexed by skill area
     - Complexity: HIGH (requires volleyball expertise)
     - Estimated effort: 6-8 weeks + domain expert collaboration

  2. Benchmark data collection
     - Aggregate anonymous stats across teams/players
     - Privacy-preserving analytics
     - Complexity: MEDIUM
     - Estimated effort: 3-4 weeks

  3. Natural language generation
     - Parent-friendly tone
     - Positive framing
     - Complexity: MEDIUM (template-based OK initially)
     - Estimated effort: 2-3 weeks

================================================================================
SECTION 2: COACH VIEW FEATURES - FEASIBILITY ANALYSIS
================================================================================

Based on mockup images (Coach-1 to Coach-4), the coach view requires:

┌─────────────────────────────────────────────────────────────────────────────┐
│ 2.1 MOMENTUM & TIMEOUT TRACKING (Coach-1.png)                              │
└─────────────────────────────────────────────────────────────────────────────┘

REQUIRED FEATURES:
  ✓ Momentum timeline visualization
  ✓ Timeout history with triggers:
    - "Alert after opponent 3-point run" ✓
  ✓ Scoring run detection:
    - "Won next 4 of 6 rallies" after timeout
  ✓ Adjustment journal:
    - "Subbed in Sarah Chen for better serve receive"
    - "Changed rotation to put Emma in back row"

CURRENT CAPABILITY:
  [NONE - 0%]

  ✗ COMPLETELY NOT IMPLEMENTED:
    - No scoreboard detection/OCR
    - No point-by-point rally tracking
    - No substitution detection
    - No rotation tracking
    - No timeout detection
    - No momentum calculation algorithm

ACCURACY CHALLENGES:
  • Scoreboard OCR reliability:
    - Varies by venue (digital vs flip-card scoreboards)
    - Requires frame-by-frame digit recognition
    - Camera angle dependency

  • Rally outcome determination:
    - WHO scored? (team A vs team B)
    - Requires ball tracking OR manual annotation

  • Substitution detection:
    - Player entering/leaving requires jersey number tracking
    - Occlusion during sub moment

IMPLEMENTATION GAPS:
  1. Scoreboard detection & OCR module
     - Detect scoreboard region in frame
     - Read digits frame-by-frame
     - Build score timeline
     - Complexity: VERY HIGH
     - Estimated effort: 6-8 weeks
     - ALTERNATIVE: Manual score entry (1 week)

  2. Rally outcome tracking
     - Same as ball tracking challenge
     - Complexity: VERY HIGH
     - Estimated effort: 6-8 weeks
     - ALTERNATIVE: HITL annotation (2 weeks for UI)

  3. Momentum calculation algorithm
     - Point differential trend
     - Rolling window analysis
     - Complexity: LOW (if score data available)
     - Estimated effort: 1 week

  4. Rotation & substitution tracking
     - Court position assignment per player per rally
     - Lineup change detection
     - Complexity: HIGH
     - Estimated effort: 4-5 weeks

┌─────────────────────────────────────────────────────────────────────────────┐
│ 2.2 ATTACK MAP & PLAY EFFECTIVENESS (Coach-2.png)                          │
└─────────────────────────────────────────────────────────────────────────────┘

REQUIRED FEATURES:
  ✓ Court placement heatmap by zone (6 zones)
  ✓ Kill rate percentage per zone:
    - Zone 4: 68% kill rate (23/34 kills)
    - Zone 3: 56% kill rate (18/32 kills)
  ✓ Play effectiveness breakdown:
    - Quick Middle: 62% success, 21 attempts
    - Outside High: 64% success, 39 attempts
    - Right Side: 58% success, 17 attempts
    - Slide: 52% success, 8 attempts
    - Back Row Attack: 35% success, 6 attempts
  ✓ "When to use" guidance:
    - "Good pass, blockers spread"
    - "Any pass quality"

CURRENT CAPABILITY:
  [PARTIAL - 25%]

  ✓ IMPLEMENTED:
    - Court detection (court/detector.py)
    - Homography for pixel-to-court mapping
    - Player position on court (CourtInfo.pixel_to_court)
    - Action type classification (spike detected)

  ✗ MISSING:
    - Court zone segmentation (6 zones not defined)
    - Attack outcome (kill vs error vs dig)
    - Play type classification (Quick Middle vs Outside High vs Slide)
    - Set quality detection (good pass vs bad pass)
    - Blocker formation analysis

ACCURACY CHALLENGES:
  • Court detection confidence: ~50-70% depending on:
    - Camera angle (overhead better than sideline)
    - Line visibility (white lines on colored floor)
    - Occlusion by players/refs

  • Court position accuracy:
    - Homography assumes flat court plane
    - Player feet position may be obscured
    - ±0.5-1.0 meter error typical

  • Play type classification:
    - Requires: set trajectory, hitter approach direction, tempo
    - Current system only knows "spike happened"
    - Cannot distinguish quick vs high vs slide

  • Attack outcome:
    - Kill: ball lands in opponent court (requires ball tracking)
    - Error: ball out/net (requires ball tracking)
    - Dig: opponent touches (requires opponent tracking + ball)

IMPLEMENTATION GAPS:
  1. Court zone definition & assignment
     - 6-zone grid overlay on court
     - Complexity: LOW
     - Estimated effort: 3-5 days

  2. Play type classifier
     - Analyze hitter approach vector + set trajectory + tempo
     - Requires: ball tracking + multiple-frame context
     - Complexity: VERY HIGH (without ball) / HIGH (with ball)
     - Estimated effort: 6-8 weeks
     - ALTERNATIVE: HITL annotation (label play types manually)

  3. Attack outcome detection
     - Same as rally outcome (needs ball tracking)
     - Complexity: VERY HIGH
     - Estimated effort: 6-8 weeks
     - ALTERNATIVE: HITL annotation (2 weeks for workflow)

  4. Set quality & blocker analysis
     - Set quality: trajectory arc, placement accuracy
     - Blocker count: detect arms at net in opponent zone
     - Complexity: HIGH
     - Estimated effort: 4-5 weeks

┌─────────────────────────────────────────────────────────────────────────────┐
│ 2.3 ROTATIONS & LINEUPS ANALYSIS (Coach-3.png)                             │
└─────────────────────────────────────────────────────────────────────────────┘

REQUIRED FEATURES:
  ✓ Rotation performance comparison:
    - R3: 78% efficiency, +42 net pts, 45 Sr / 33 against
    - R1: 71% efficiency, -7 net pts
    - R4: 64% efficiency, -4 net pts
  ✓ Lineup effectiveness rankings:
    - Lineup A: Starters (85% win rate, 12 sets)
    - Lineup B: Strong serve (72% win rate, 98/87)
    - Lineup C: In=M3, Out=O2 (68% win rate, 112/103)
  ✓ Player confidence level indicators (High/Med/Low)

CURRENT CAPABILITY:
  [NONE - 0%]

  ✗ COMPLETELY NOT IMPLEMENTED:
    - No rotation tracking (R1-R6)
    - No lineup detection (which 6 players on court)
    - No score-by-rotation aggregation
    - No player confidence metrics

ACCURACY CHALLENGES:
  • Rotation identification:
    - Requires: knowing which rotation (R1-R6) team is in
    - Depends on: serve order, player positions, scoreboard
    - Very complex to infer from video alone

  • Lineup detection:
    - Requires: identifying all 6 players on court simultaneously
    - Jersey number OCR for each player
    - Substitution tracking

  • Confidence metrics:
    - Highly subjective
    - Cannot be reliably auto-detected from video
    - Requires coach/player input OR body language ML (very hard)

IMPLEMENTATION GAPS:
  1. Rotation tracking system
     - Infer rotation from player court positions
     - Requires robust player ID + position tracking
     - Complexity: VERY HIGH
     - Estimated effort: 8-10 weeks
     - ALTERNATIVE: Manual rotation entry (1-2 weeks for UI)

  2. Lineup detection & tracking
     - Identify 6 on-court players per rally
     - Track substitutions
     - Complexity: HIGH
     - Estimated effort: 5-6 weeks

  3. Score-by-rotation aggregation
     - IF rotation data available: easy aggregation
     - Complexity: LOW (given rotation data)
     - Estimated effort: 1 week

  4. Confidence metrics
     - REQUIRES: Human input (coach/player surveys)
     - Auto-detection not feasible
     - Complexity: N/A (manual data)

┌─────────────────────────────────────────────────────────────────────────────┐
│ 2.4 DASHBOARD & RECOMMENDED ADJUSTMENTS (Coach-4.png)                      │
└─────────────────────────────────────────────────────────────────────────────┘

REQUIRED FEATURES:
  ✓ Quick insights dashboard:
    - Best Rotation: R3 (78% efficiency)
    - Weak Rotation: R6 (62% efficiency, -4 net pts)
    - Best Lineup: Lineup A (85% win rate)
    - Play Performance: Best=Quick Middle, Struggle=Back Row Attack
  ✓ Recommended adjustments:
    1. "Rotation 6 is losing points (set -4)" → Adjust timing
    2. "Zones 2&4 are highest kill rate (68%)" → Guide hitters
    3. "Back Row Attack has lowest success (35%)" → Selectively use
  ✓ Coach notes workflow:
    - Celebrate + Focus
    - Tough Match + Growth
    - Tournament Recap
  ✓ Draft/Published state management
  ✓ Highlight & learning clip attachment

CURRENT CAPABILITY:
  [MINIMAL - 10%]

  ✓ IMPLEMENTED:
    - Basic stats aggregation (VideoStats, PlayerStats)
    - Action distribution calculation

  ✗ MISSING:
    - Rotation-level analytics (not tracked)
    - Lineup-level analytics (not tracked)
    - Zone-level analytics (zones not defined)
    - Play-type analytics (play types not classified)
    - Insight generation engine
    - Coach notes authoring interface
    - Draft/publish workflow
    - Auto-attach relevant clips to notes

ACCURACY CHALLENGES:
  • All downstream analytics depend on upstream accuracy:
    - Rotation tracking accuracy
    - Play type classification accuracy
    - Attack outcome detection accuracy

  • Recommendation quality depends on:
    - Statistical significance (enough data?)
    - Context understanding (opponent strength? tournament pressure?)

IMPLEMENTATION GAPS:
  1. Analytics aggregation engine
     - Roll up stats by rotation, lineup, zone, play type
     - Complexity: MEDIUM (given upstream data)
     - Estimated effort: 2-3 weeks

  2. Insight generation & recommendation engine
     - Template-based insights: "Rotation X is struggling"
     - Threshold detection: rotation efficiency < 65% → flag
     - Complexity: MEDIUM
     - Estimated effort: 3-4 weeks

  3. Coach notes authoring UI
     - Rich text editor
     - Clip attachment
     - Draft/publish workflow
     - Sharing to parent view
     - Complexity: MEDIUM (full-stack)
     - Estimated effort: 4-5 weeks

  4. Parent view integration
     - Coach notes appear in parent "What to Work on Next"
     - Complexity: LOW
     - Estimated effort: 1 week

================================================================================
SECTION 3: MODEL ACCURACY CHALLENGES & LIMITATIONS
================================================================================

┌─────────────────────────────────────────────────────────────────────────────┐
│ 3.1 PLAYER DETECTION & TRACKING ACCURACY                                   │
└─────────────────────────────────────────────────────────────────────────────┘

CURRENT SYSTEM:
  • Model: YOLOv8n (nano variant for speed)
  • Confidence threshold: 0.4 (per config)
  • Tracker: ByteTrack with Re-ID

ACCURACY METRICS (Estimated from typical volleyball video):
  • Detection recall: ~85-90%
    - Misses: distant players, partial occlusions, motion blur
  • Detection precision: ~75-80%
    - False positives: referees, fans near court edge, ball boys
  • Tracking ID consistency: ~70-75% across full game
    - ID switches occur during:
      - Heavy occlusions (net traffic during rallies)
      - Player substitutions (new player gets new ID)
      - Camera angle changes
      - Players crossing paths

FAILURE MODES:
  1. Occlusion cascades
     - Player behind net → detection lost → track terminated
     - When player reappears → assigned new track ID
     - Mitigation: Increased track_buffer (150 frames = 5 sec)

  2. Similar appearance confusion
     - Same-team players with similar jerseys
     - ByteTrack Re-ID uses appearance features
     - Can swap IDs between similar-looking players
     - Mitigation: Jersey number OCR (NOT implemented)

  3. False positive spectators
     - Edge filtering helps (5% margin)
     - But fans near court can still be detected
     - Mitigation: Court mask filtering (implemented but ~70% accurate)

  4. Partial player detections
     - Crouching player → small bbox → filtered out by size
     - Player diving → horizontal aspect ratio → filtered out
     - Mitigation: Relaxed size filters in config (implemented)

IMPACT ON DOWNSTREAM ANALYTICS:
  • ID switches → fragmented player statistics
    - Player 5 might be tracked as ID=3 in set 1, ID=7 in set 2
    - Segment merging helps (merge_segments_by_track) but not perfect

  • False positives → inflated player counts
    - "12 players detected" might include refs, coaches

  • Detection drops → missed actions
    - If player not detected → no pose → no action classification
    - Serve at edge of frame might be missed entirely

┌─────────────────────────────────────────────────────────────────────────────┐
│ 3.2 POSE ESTIMATION ACCURACY                                               │
└─────────────────────────────────────────────────────────────────────────────┘

CURRENT SYSTEM:
  • Model: MediaPipe Pose (model_complexity=1)
  • 33 keypoints per person
  • Processes cropped player bounding boxes

ACCURACY METRICS:
  • Keypoint detection rate: ~80-85% for visible keypoints
    - Better for: upper body (shoulders, elbows, wrists)
    - Worse for: lower body when occluded by net/other players

  • Pose confidence by scenario:
    - Standing/idle: 85-90% confidence
    - Jumping: 70-75% confidence (motion blur)
    - Crouching/digging: 65-70% confidence (unusual poses)
    - Occluded: 40-60% confidence (partial visibility)

FAILURE MODES:
  1. Motion blur during fast actions
     - Spike swing: arm is blurred → wrist position uncertain
     - Jump serve toss: hand motion blurred
     - Impact: Action classification relies on hand positions

  2. Occlusion by net, ball, other players
     - Blocker's hands above net → keypoints lost
     - Setter behind front row → torso/legs occluded
     - Impact: Cannot calculate knee angles, body lean

  3. Unusual body positions
     - Diving dig: horizontal body → MediaPipe trained on upright poses
     - Pancake dig: hand flat on floor → unusual wrist angle
     - Impact: Keypoints may be hallucinated incorrectly

  4. Multiple people in crop (rare)
     - If two players very close, crop includes both
     - MediaPipe detects one skeleton → merges keypoints
     - Impact: Garbage pose data

IMPACT ON ACTION CLASSIFICATION:
  • Hand position errors → serve/spike confusion
    - If wrist position is off by 50 pixels → might miss "one arm high"

  • Knee angle errors → ready/dig/idle confusion
    - Partially occluded legs → cannot determine crouch

  • Missing keypoints → classification defaults to UNKNOWN
    - If <30% keypoints visible → classifier gives up
    - Segments with UNKNOWN action are filtered out

┌─────────────────────────────────────────────────────────────────────────────┐
│ 3.3 ACTION CLASSIFICATION ACCURACY                                         │
└─────────────────────────────────────────────────────────────────────────────┘

CURRENT SYSTEM:
  • Approach: Rule-based heuristics (actions/classifier.py)
  • Features: Hand height, arm angles, knee angles, arm symmetry
  • No ML model, no temporal context (only 5-frame history smoothing)

ESTIMATED ACCURACY BY ACTION:

  SERVE: ~70%
    ✓ Good indicators:
      - One arm high (toss or contact)
      - Standing upright (not crouched)
      - Asymmetric arm positions
    ✗ Confusion sources:
      - Setting from back row (similar arm position)
      - Reaching for high ball (one arm up)

  SPIKE: ~65%
    ✓ Good indicators:
      - Very high hand (above head)
      - Asymmetric arms (one arm swinging)
    ✗ Confusion sources:
      - Serve contact (very similar pose)
      - Jump to block (high hands but symmetric)
      - Temporal context missing (can't see approach)

  BLOCK: ~75%
    ✓ Good indicators:
      - Both arms raised high
      - Symmetric arm positions (>0.7 symmetry)
    ✗ Confusion sources:
      - Celebrating with arms up
      - Setting a high ball (hands at head level)

  DIG: ~60%
    ✓ Good indicators:
      - Deep crouch (<100° knee angle)
      - Hands together (platform)
    ✗ Confusion sources:
      - Ready position (also crouched)
      - Pass/receive (same platform position)
      - Standing digs (no crouch)

  SET: ~55%
    ✓ Good indicators:
      - Hands near face/head
      - Symmetric arms
    ✗ Confusion sources:
      - Blocking (hands high)
      - Receiving high ball
      - Adjusting hair/face

  RECEIVE/PASS: ~50%
    ✓ Good indicators:
      - Hands together (platform)
      - Not deeply crouched
    ✗ Confusion sources:
      - Dig (same platform)
      - Ready position
      - Overlap with RECEIVE action type

  READY/IDLE: ~70%
    ✓ Good indicators:
      - Not performing active action
      - Standing or slight crouch
    ✗ Confusion sources:
      - False positives: actual actions missed → default to ready

FUNDAMENTAL LIMITATIONS OF RULE-BASED APPROACH:

  1. NO TEMPORAL CONTEXT
     - Serve = toss → contact → follow-through (3 phases)
     - Current system sees ONE FRAME at a time
     - Cannot distinguish toss phase from set phase

  2. NO BALL AWARENESS
     - Spike is "hitting toward ball"
     - Set is "hands directing ball overhead"
     - Without ball tracking, rules are ambiguous

  3. NO GAME STATE UNDERSTANDING
     - Serve only happens when server is in back right
     - Spike only happens on attack
     - Rules don't know who has possession

  4. POSE AMBIGUITY
     - Many actions share similar poses:
       - Serve contact ≈ Spike contact
       - Set ≈ Block preparation
       - Dig ≈ Pass ≈ Ready

  5. NO CONFIDENCE CALIBRATION
     - Confidence scores are heuristic (not probabilistic)
     - 0.7 confidence doesn't mean "70% probability correct"

IMPACT ON USER FEATURES:
  • Attack points counting: ~70% accurate
    - Overcounts: blocks as spikes
    - Undercounts: missed detections

  • Serve stats: ~75% accurate
    - Better than other actions
    - Still cannot track aces (need ball outcome)

  • "Plays to review": LOW quality
    - Auto-detected highlights may be wrong actions
    - Frustrating user experience if wrong

  • Coaching insights: NOT RELIABLE
    - "You spiked 15 times" → actually 10 spikes, 5 blocks
    - Recommendations based on bad data → mistrust

┌─────────────────────────────────────────────────────────────────────────────┐
│ 3.4 COURT DETECTION ACCURACY                                               │
└─────────────────────────────────────────────────────────────────────────────┘

CURRENT SYSTEM:
  • Approach: Line detection (Hough transform) + homography
  • Detects: court corners, sidelines, baselines, center line
  • Output: Court mask, pixel-to-court coordinate transform

ACCURACY METRICS:
  • Court detection success rate: ~60-70%
    - Success = finds 4 corners with confidence > 0.3

  • Homography accuracy: ±0.5-1.0 meter error
    - Better: overhead camera, clear lines, minimal players
    - Worse: sideline camera, worn lines, crowded court

FAILURE MODES:
  1. Poor camera angle
     - Sideline view: court appears foreshortened
     - Far corner is compressed → distortion
     - Homography assumes flat plane → perspective error

  2. Line visibility issues
     - Worn white lines on old gym floors
     - Shadows from overhead lights
     - Advertising banners near court edges

  3. Dynamic occlusions
     - Players standing on lines
     - Referees blocking court corners
     - Line detection changes frame-to-frame

  4. Multiple courts in frame
     - Gyms with adjacent courts
     - Hough lines from neighboring court
     - False corner detection

IMPACT ON FEATURES:
  • Attack map zones: ±1 zone error
    - Player in Zone 4 might be mapped to Zone 3
    - Zone-level kill rates are approximate

  • Player filtering by court: ~80% effective
    - 20% false rejections: actual player filtered out
    - 10% false accepts: spectator near court included

  • Court position for insights: LOW confidence
    - Cannot reliably say "player is at net" vs "3m back"

┌─────────────────────────────────────────────────────────────────────────────┐
│ 3.5 MISSING CAPABILITIES (NOT IMPLEMENTED)                                 │
└─────────────────────────────────────────────────────────────────────────────┘

CRITICAL MISSING COMPONENTS:

  1. BALL TRACKING
     - Why critical: Needed for ALL outcome detection
       - Serve ace vs fault
       - Spike kill vs error
       - Dig success vs miss
       - Rally win/loss
     - Complexity: VERY HIGH
       - Ball is small (5-10 pixels diameter)
       - Fast motion (60+ mph on spikes)
       - Frequent occlusions (behind players, net)
       - Color similar to floor/walls
     - Estimated accuracy if implemented: 50-60%
       - Would miss ~40% of ball positions
       - Tracking would break during occlusions
     - Estimated effort: 6-8 weeks

  2. JERSEY NUMBER OCR
     - Why critical: Player identity persistence across games
     - Complexity: MEDIUM-HIGH
       - Need to detect number region on player bbox
       - OCR on motion-blurred, angled numbers
       - Same number on front and back (different views)
     - Estimated accuracy if implemented: 70-80%
       - Fail on: motion blur, occlusion, rotated players
     - Estimated effort: 2-3 weeks

  3. SCOREBOARD OCR
     - Why critical: Point-by-point tracking, momentum
     - Complexity: HIGH
       - Scoreboard location varies by venue
       - Digital vs flip-card scoreboards
       - Small region in frame (low resolution)
     - Estimated accuracy if implemented: 60-70%
       - Fail on: glare, low res, non-standard scoreboards
     - Estimated effort: 4-5 weeks
     - ALTERNATIVE: Manual score entry (much easier)

  4. ROTATION TRACKING
     - Why critical: Rotation-level analytics
     - Complexity: VERY HIGH
       - Need to infer rotation from court positions
       - Requires perfect player ID + position tracking
       - Ambiguous without scoreboard context
     - Estimated accuracy if implemented: 40-50%
       - Too many failure modes
     - Estimated effort: 8-10 weeks
     - ALTERNATIVE: Manual rotation entry (1-2 weeks)

  5. PLAY TYPE CLASSIFICATION
     - Why critical: Play effectiveness stats (Quick Middle, Slide, etc.)
     - Complexity: VERY HIGH
       - Requires ball trajectory + hitter approach + setter location
       - Temporal context (3-5 second window)
       - Domain-specific taxonomy (volleyball plays)
     - Estimated accuracy if implemented: 30-40%
       - Too many play variations
     - Estimated effort: 6-8 weeks
     - ALTERNATIVE: HITL annotation (2-3 weeks for UI)

================================================================================
SECTION 4: HUMAN-IN-THE-LOOP (HITL) SOLUTION STRATEGY
================================================================================

Given the accuracy limitations and missing capabilities, a Human-in-the-Loop
approach is ESSENTIAL to deliver the North Star vision.

┌─────────────────────────────────────────────────────────────────────────────┐
│ 4.1 HITL WORKFLOW DESIGN                                                   │
└─────────────────────────────────────────────────────────────────────────────┘

CORE PRINCIPLE:
  "AI does the heavy lifting, Humans do the judgment"

  ┌─────────────────────────────────────────────────────────────────┐
  │ CURRENT PURE ML APPROACH (Not Feasible)                        │
  ├─────────────────────────────────────────────────────────────────┤
  │ Video → Detection → Tracking → Pose → Action → Insights        │
  │         ↓           ↓          ↓       ↓         ↓             │
  │        85%         70%        75%     60%       30%            │
  │                                                                 │
  │ CUMULATIVE ACCURACY: 85% × 70% × 75% × 60% × 30% = 8%         │
  │                                                                 │
  │ RESULT: Garbage output, user frustration                       │
  └─────────────────────────────────────────────────────────────────┘

  ┌─────────────────────────────────────────────────────────────────┐
  │ PROPOSED HITL APPROACH (Feasible)                              │
  ├─────────────────────────────────────────────────────────────────┤
  │ Video → Detection → Tracking → Pose → Action → [HITL REVIEW]  │
  │         ↓           ↓          ↓       ↓         ↓             │
  │        85%         70%        75%     60%       95%            │
  │                                                                 │
  │ Human reviewer corrects:                                       │
  │  - Player identities (jersey number tagging)                   │
  │  - Action classifications (serve vs spike)                     │
  │  - Rally outcomes (kill vs error)                              │
  │  - Moment categorization (highlight vs learning)               │
  │  - Coach notes (why this matters)                              │
  │                                                                 │
  │ CUMULATIVE ACCURACY: 85% × 70% × 75% × 60% × 95% = 27%        │
  │ BUT: Human corrects final step → 95% FINAL ACCURACY            │
  └─────────────────────────────────────────────────────────────────┘

HITL WORKFLOW STAGES:

  STAGE 1: Automated Processing (No human required)
    Input: Raw video file
    Process:
      1. Player detection & tracking → track IDs
      2. Pose estimation → keypoints
      3. Action classification → tentative labels
      4. Segment extraction → candidate clips
    Output: Draft analysis with low confidence
    Time: ~2-5 minutes per 1-hour video (on GPU)

  STAGE 2: Human Review & Correction (Coach/Analyst workflow)
    Input: Draft analysis + video
    Interface: Web-based review tool
    Tasks:
      ┌───────────────────────────────────────────────────────────┐
      │ TASK 2A: Player Identity Tagging (5-10 min)              │
      ├───────────────────────────────────────────────────────────┤
      │ UI shows: All detected track IDs                          │
      │ User action: Assign name + jersey # to each track        │
      │           Merge duplicate tracks for same player          │
      │ AI assist: Suggest names based on position/appearance    │
      │ Output: track_id → player mapping                         │
      └───────────────────────────────────────────────────────────┘

      ┌───────────────────────────────────────────────────────────┐
      │ TASK 2B: Action Verification (10-15 min)                  │
      ├───────────────────────────────────────────────────────────┤
      │ UI shows: All auto-detected action segments               │
      │        Grid view with video thumbnail for each            │
      │ User action: ✓ Correct / ✗ Delete / ✏ Relabel            │
      │ AI assist: Sort by confidence (low confidence first)      │
      │          Highlight uncertain segments                     │
      │ Output: Verified action segments                          │
      └───────────────────────────────────────────────────────────┘

      ┌───────────────────────────────────────────────────────────┐
      │ TASK 2C: Rally Outcome Annotation (15-20 min)             │
      ├───────────────────────────────────────────────────────────┤
      │ UI shows: Detected serves/spikes                          │
      │ User action: Mark outcome (Kill/Error/Dig/Ace/Fault)     │
      │ AI assist: Pre-fill based on next action sequence        │
      │            (spike → no opponent action → likely kill)     │
      │ Output: Rally outcomes for attack stats                   │
      └───────────────────────────────────────────────────────────┘

      ┌───────────────────────────────────────────────────────────┐
      │ TASK 2D: Highlight Selection (5-10 min)                   │
      ├───────────────────────────────────────────────────────────┤
      │ UI shows: Top 20 action clips by ML confidence            │
      │ User action: Star as "Highlight" or "Learning Moment"    │
      │          Add category (Great Execution / Hustle / Learn)  │
      │ AI assist: Auto-suggest based on action quality           │
      │ Output: Curated highlight reel                            │
      └───────────────────────────────────────────────────────────┘

      ┌───────────────────────────────────────────────────────────┐
      │ TASK 2E: Coach Notes Authoring (10-15 min)                │
      ├───────────────────────────────────────────────────────────┤
      │ UI shows: Stats summary + insights                        │
      │ User action: Write "What to work on next" notes           │
      │          Select drill templates                           │
      │          Add "Why this matters" explanations              │
      │ AI assist: Pre-fill templates with player stats           │
      │          "Sarah's serve accuracy is 85% (↑12% vs last)"   │
      │ Output: Personalized coaching notes                       │
      └───────────────────────────────────────────────────────────┘

    Total human time: 45-70 minutes per 1-hour match

  STAGE 3: Automated Finalization (No human required)
    Input: Verified data + coach notes
    Process:
      1. Aggregate stats (per player, rotation, lineup, zone)
      2. Generate insights (rotation efficiency, play success)
      3. Create highlight clips with annotations
      4. Render parent/coach dashboards
    Output: Final analysis ready for sharing
    Time: ~1-2 minutes

  STAGE 4: Parent/Coach Consumption
    Output: Web dashboard with insights, clips, notes
    No further human effort required

┌─────────────────────────────────────────────────────────────────────────────┐
│ 4.2 HITL INTERFACE REQUIREMENTS                                            │
└─────────────────────────────────────────────────────────────────────────────┘

REQUIRED UI COMPONENTS:

  1. VIDEO ANNOTATION WORKSPACE
     - Timeline scrubber with detected actions overlaid
     - Multi-track view (1 row per player)
     - Keyboard shortcuts for rapid labeling:
       - S = serve, P = spike, B = block, D = dig, T = set
       - K = kill, E = error, A = ace, F = fault
     - Drag-to-adjust segment boundaries

  2. PLAYER IDENTITY MANAGER
     - Gallery view of all track IDs (thumbnail per ID)
     - Drag-and-drop to merge duplicate tracks
     - Text input for name + jersey number
     - Auto-complete from team roster

  3. ACTION CLIP REVIEWER
     - Grid of video thumbnails (3-4 sec clips)
     - ✓ / ✗ / ✏ buttons per clip
     - Dropdown to change action label
     - Confidence score indicator

  4. RALLY OUTCOME ANNOTATOR
     - Split-screen: video playback + outcome buttons
     - Click outcome → auto-advance to next rally
     - Undo/redo support

  5. HIGHLIGHT CURATOR
     - Side-by-side: clip list + video player
     - Star rating (1-5 stars)
     - Category tags (Highlight / Learn / Hustle)
     - Bulk operations (delete all <2 stars)

  6. COACH NOTES EDITOR
     - Rich text editor with templates
     - Variable insertion: {{player_name}}, {{serve_pct}}
     - Drill library browser
     - Attach video clips to notes
     - Preview parent view before publishing

TECHNICAL STACK RECOMMENDATIONS:

  Frontend:
    - React + TypeScript
    - Video player: Video.js or Plyr
    - Timeline: vis-timeline or custom Canvas
    - Drag-and-drop: react-beautiful-dnd

  Backend:
    - FastAPI (Python) for API
    - PostgreSQL for data storage
    - S3 for video/clip storage
    - Redis for job queue (video processing)

  Video Processing:
    - Celery for async task management
    - FFmpeg for clip extraction
    - Current Python pipeline (volley_analytics) as worker

  Deployment:
    - Docker containers
    - AWS ECS or Kubernetes for scaling
    - CloudFront CDN for video delivery

┌─────────────────────────────────────────────────────────────────────────────┐
│ 4.3 HITL DATA FLYWHEEL STRATEGY                                            │
└─────────────────────────────────────────────────────────────────────────────┘

VIRTUOUS CYCLE:

  ┌──────────────────────────────────────────────────────────────┐
  │                                                              │
  │  Human corrections → Training data → Better models →        │
  │       ↑                                            ↓         │
  │       └────────────── Less human effort ───────────┘         │
  │                                                              │
  └──────────────────────────────────────────────────────────────┘

PHASE 1: HITL-Intensive (Months 1-6)
  - Human corrects 80% of auto-detected actions
  - ~60 min/match of human effort
  - Collect training data:
    - 1000 hours of annotated video
    - 100,000+ labeled action segments
    - 50,000+ verified rally outcomes

PHASE 2: ML Improvement (Months 6-12)
  - Train action classifier on corrected data
  - Current rule-based (60%) → ML-based (75%)
  - Human effort reduced to ~40 min/match (30% reduction)
  - Collect more training data

PHASE 3: Refined Models (Months 12-18)
  - Train play type classifier
  - Train rally outcome predictor
  - Human effort reduced to ~25 min/match (60% reduction)
  - Focus shifts to edge cases only

PHASE 4: AI-Assisted (Months 18+)
  - Most actions auto-verified with high confidence
  - Human only reviews flagged uncertain segments (~10%)
  - Human effort reduced to ~15 min/match (75% reduction)
  - Primary value: coach notes authoring (AI can't replace)

TRAINING DATA PRIORITIES:

  Priority 1: Action classification
    - Collect: serve, spike, block, dig, set labels
    - Annotation: 10,000 clips per action type
    - Expected improvement: 60% → 80% accuracy

  Priority 2: Rally outcomes
    - Collect: kill, error, ace, fault labels
    - Annotation: 5,000 rallies
    - Expected improvement: enable attack % stats

  Priority 3: Play types
    - Collect: quick middle, outside high, slide, etc.
    - Annotation: 3,000 plays
    - Expected improvement: enable play effectiveness stats

  Priority 4: Player Re-ID
    - Collect: same-player track associations
    - Annotation: 500 matches worth of track merges
    - Expected improvement: 70% → 85% ID consistency

DATA COLLECTION WORKFLOW:

  1. Every HITL correction is logged:
     - Original ML prediction
     - Human correction
     - Timestamp
     - Video frame reference

  2. Nightly batch export to training dataset

  3. Monthly model retraining:
     - Retrain action classifier
     - Evaluate on held-out test set
     - Deploy if improvement > 2%

  4. Quarterly model major updates:
     - Integrate new model architectures
     - Add new features (ball tracking, etc.)

┌─────────────────────────────────────────────────────────────────────────────┐
│ 4.4 WHICH TASKS TO AUTOMATE vs. ALWAYS REQUIRE HUMAN                       │
└─────────────────────────────────────────────────────────────────────────────┘

AUTOMATION POTENTIAL MATRIX:

  ┌────────────────────────┬────────────┬─────────────┬──────────────┐
  │ TASK                   │ CURRENT ML │ FUTURE ML   │ ALWAYS HUMAN │
  ├────────────────────────┼────────────┼─────────────┼──────────────┤
  │ Player detection       │    85%     │    90%      │      No      │
  │ Player tracking        │    70%     │    85%      │      No      │
  │ Pose estimation        │    75%     │    80%      │      No      │
  │ Action classification  │    60%     │    80%      │      No      │
  │ Court detection        │    65%     │    75%      │      No      │
  │ Jersey # recognition   │     0%     │    75%      │      No      │
  │ Player identity        │     0%     │    60%      │  **Yes**     │
  │ Rally outcome          │     0%     │    70%      │  **Yes**     │
  │ Play type              │     0%     │    60%      │  **Yes**     │
  │ Moment categorization  │     0%     │    50%      │  **Yes**     │
  │ Coaching insights      │     0%     │    40%      │  **Yes**     │
  │ "Why this matters"     │     0%     │     0%      │  **YES**     │
  │ Parent communication   │     0%     │     0%      │  **YES**     │
  └────────────────────────┴────────────┴─────────────┴──────────────┘

RATIONALE:

  CAN BE AUTOMATED (with training data):
    - Low-level perception: detection, tracking, pose
    - Objective classification: action types, play types
    - Factual labeling: jersey numbers, rally outcomes

  MUST REMAIN HUMAN:
    - Subjective evaluation: "This is a great learning moment"
    - Contextual judgment: "She's improving under pressure"
    - Emotional intelligence: "Frame it positively for parents"
    - Domain expertise: "This is a good time to run Quick Middle"
    - Coach-player relationship: Personal knowledge of player's goals

RECOMMENDED DIVISION OF LABOR:

  Automated (90% of processing time):
    - Video ingestion & frame extraction
    - Player detection & tracking
    - Pose estimation
    - Action segment proposal
    - Statistics aggregation
    - Clip extraction & encoding

  Human-in-the-Loop (10% of processing time, 100% of value):
    - Player identity confirmation (1-time per season)
    - Action verification (spot-check 20% of segments)
    - Rally outcome tagging (critical for stats)
    - Highlight curation (pick top moments)
    - Coach notes authoring (personalized insights)

================================================================================
SECTION 5: IMPLEMENTATION ROADMAP
================================================================================

RECOMMENDED PHASED APPROACH:

┌─────────────────────────────────────────────────────────────────────────────┐
│ PHASE 1: MVP - PARENT VIEW BASICS (8-10 weeks)                             │
└─────────────────────────────────────────────────────────────────────────────┘

GOAL: Deliver basic parent value with manual coach input

FEATURES:
  ✓ Upload video → automated processing (existing pipeline)
  ✓ Coach identity tagging (manual UI)
  ✓ Action verification UI (correct auto-labels)
  ✓ Basic stats: serve count, spike count, dig count
  ✓ Highlight clip selection (coach picks top 5)
  ✓ Simple parent dashboard:
    - Player name + number
    - Action counts
    - Highlight video clips
    - Coach notes (text only)

SCOPE CUTS:
  ✗ No rally outcomes (no kill %, ace %, etc.)
  ✗ No attack map / zones
  ✗ No rotation tracking
  ✗ No lineup analysis
  ✗ No "What to work on next" insights (coach writes freeform)
  ✗ No momentum tracking

DELIVERABLES:
  1. Video processing pipeline (already exists, needs web wrapper)
  2. Coach review UI (new web app)
     - Player tagging interface
     - Action clip reviewer
     - Highlight selector
     - Notes editor
  3. Parent dashboard (new web app)
     - Player profile page
     - Stats summary
     - Highlight clips with embedded player
  4. Backend API (FastAPI)
     - Video upload
     - Processing job queue
     - Data storage (PostgreSQL)
  5. Video storage & delivery (S3 + CloudFront)

ENGINEERING EFFORT:
  - Backend API: 2 weeks
  - Coach review UI: 3-4 weeks
  - Parent dashboard: 2-3 weeks
  - Video pipeline integration: 1-2 weeks
  - Testing & deployment: 1 week

TOTAL: 9-12 weeks with 2 engineers

SUCCESS METRICS:
  - 10 beta coach users
  - 50 parent users
  - 100 videos processed
  - <5 min avg human review time per video
  - >80% parent satisfaction ("This is useful")

┌─────────────────────────────────────────────────────────────────────────────┐
│ PHASE 2: COACH VIEW + RALLY OUTCOMES (6-8 weeks)                           │
└─────────────────────────────────────────────────────────────────────────────┘

GOAL: Add coach-specific features and meaningful stats

FEATURES:
  ✓ Rally outcome annotation UI
    - Serve: ace / fault / in play
    - Spike: kill / error / dig
  ✓ Attack stats:
    - Attack %: kills / total attempts
    - Serve %: aces + in play / total serves
  ✓ Court zones (6 zones) with attack map
  ✓ Performance comparison (vs last 5 games)
  ✓ Coach dashboard with insights:
    - Top performer by kill %
    - Serve leader
    - Improvement alerts ("Sarah's hitting is up 15%")
  ✓ Parent view enhancements:
    - Attack % on stats page
    - Zone heatmap (simplified)

DELIVERABLES:
  1. Rally outcome annotator UI
  2. Court zone detection & assignment (extend court/detector.py)
  3. Attack map visualization
  4. Coach dashboard
  5. Multi-game database schema
  6. Comparison analytics engine

ENGINEERING EFFORT:
  - Rally annotator UI: 2 weeks
  - Court zones: 1 week
  - Attack map viz: 2 weeks
  - Coach dashboard: 2-3 weeks
  - Multi-game DB: 1 week

TOTAL: 8-10 weeks with 2 engineers

SUCCESS METRICS:
  - 30 active coach users
  - 200 videos processed
  - >90% rally outcome annotation completion rate
  - Coach time <10 min/video (automation improving)

┌─────────────────────────────────────────────────────────────────────────────┐
│ PHASE 3: ML IMPROVEMENTS + AUTOMATION (8-10 weeks)                         │
└─────────────────────────────────────────────────────────────────────────────┘

GOAL: Reduce coach workload via better ML models

FEATURES:
  ✓ Train action classifier on HITL-corrected data
    - Target: 60% → 75% accuracy
  ✓ Jersey number OCR (reduce identity tagging burden)
  ✓ Rally outcome prediction (pre-fill annotations)
  ✓ Confidence-based review routing:
    - High confidence (>0.8): auto-approve
    - Medium (0.5-0.8): coach spot-checks 20%
    - Low (<0.5): coach reviews all
  ✓ Improved tracking (better Re-ID model)
  ✓ Auto-merge duplicate player tracks

DELIVERABLES:
  1. Action classification ML model
     - Data: 10k labeled clips from Phase 1-2
     - Model: Temporal CNN (3D Conv or Transformer)
     - Training pipeline
  2. Jersey number OCR module
     - YOLO for number detection
     - OCR for digit recognition
  3. Rally outcome predictor (heuristic rules initially)
  4. Confidence-based review workflow
  5. Improved ByteTrack Re-ID features

ENGINEERING EFFORT:
  - ML model training: 3-4 weeks
  - Jersey OCR: 2-3 weeks
  - Rally predictor: 1-2 weeks
  - Review workflow: 1 week
  - Re-ID improvements: 2 weeks

TOTAL: 9-12 weeks with 2 engineers + 1 ML engineer

SUCCESS METRICS:
  - Action classification: 60% → 75%+
  - Jersey recognition: 70%+ accuracy
  - Coach time: <10 min → <6 min per video (40% reduction)
  - Auto-approved segments: 50%+ (high confidence)

┌─────────────────────────────────────────────────────────────────────────────┐
│ PHASE 4: ADVANCED FEATURES (12+ weeks)                                     │
└─────────────────────────────────────────────────────────────────────────────┘

GOAL: Full North Star feature set

FEATURES:
  ✓ Rotation tracking (manual entry or auto-detect)
  ✓ Lineup effectiveness analysis
  ✓ Momentum timeline (requires scoring data)
  ✓ Play type classification (Quick Middle, Slide, etc.)
  ✓ "What to work on next" insight engine
  ✓ Drill recommendation system
  ✓ Parent communication templates
  ✓ Mobile app for parent access

SCOPE:
  - Rotation: Manual entry UI (auto-detect too hard)
  - Scoring: Manual score entry OR scoreboard OCR
  - Play types: HITL annotation initially, ML later
  - Insights: Template-based with coach review

DELIVERABLES:
  1. Rotation entry UI + tracking
  2. Lineup effectiveness analytics
  3. Scoring/momentum system
  4. Play type annotation workflow
  5. Insight generation engine
  6. Drill database
  7. Mobile app (React Native)

ENGINEERING EFFORT:
  - Rotation tracking: 3 weeks
  - Lineup analytics: 2 weeks
  - Momentum system: 3 weeks
  - Play type workflow: 2-3 weeks
  - Insight engine: 4 weeks
  - Mobile app: 6-8 weeks

TOTAL: 20-25 weeks with 3 engineers

SUCCESS METRICS:
  - 100+ active coaches
  - 1000+ parent users
  - 5000+ videos processed
  - <5 min coach time per video (75% reduction from Phase 1)
  - NPS score >50

================================================================================
SECTION 6: CRITICAL RECOMMENDATIONS
================================================================================

┌─────────────────────────────────────────────────────────────────────────────┐
│ 6.1 DO-ABLE NOW (With HITL)                                                │
└─────────────────────────────────────────────────────────────────────────────┘

✓ Player profile with season highlights (coach-curated)
✓ Action counts (serve, spike, block, dig) with ~70% accuracy
✓ Video highlight clips (coach-selected)
✓ Basic performance stats (counts, not percentages)
✓ Comparison across games (with multi-game DB)
✓ Coach notes and "What to work on next" (coach-authored)
✓ Court zones for attack map (with manual correction)
✓ Parent dashboard with stats + clips

┌─────────────────────────────────────────────────────────────────────────────┐
│ 6.2 NOT DO-ABLE FULLY AUTOMATED (Requires HITL)                            │
└─────────────────────────────────────────────────────────────────────────────┘

⚠ Attack success % (kill vs error) → Needs rally outcome annotation
⚠ Serve ace detection → Needs rally outcome annotation
⚠ Rotation effectiveness → Needs manual rotation entry
⚠ Lineup analysis → Needs manual lineup tracking
⚠ Momentum tracking → Needs scoring data (manual or OCR)
⚠ Play type classification → Needs HITL annotation
⚠ "Why this matters" insights → Needs coach authoring
⚠ Confidence metrics → Needs subjective coach input
⚠ "Hustle plays" → Needs coach judgment

┌─────────────────────────────────────────────────────────────────────────────┐
│ 6.3 NOT DO-ABLE AT ALL (Even with HITL, Too Complex)                       │
└─────────────────────────────────────────────────────────────────────────────┘

✗ Fully automated rally outcome detection (ball tracking too hard)
✗ Automatic play type classification (too many variations)
✗ Automatic rotation detection (too ambiguous)
✗ Automatic "learning moment" detection (subjective)
✗ Automatic parent communication tone (requires EQ)

WORKAROUNDS:
  → Rally outcomes: Manual annotation (fast UI, <20 min/match)
  → Play types: Coach labels plays, ML learns patterns over time
  → Rotations: Coach enters rotation at start of each set
  → Learning moments: Coach flags clips, adds "why"
  → Parent tone: Coach reviews AI-generated drafts

┌─────────────────────────────────────────────────────────────────────────────┐
│ 6.4 ACCURACY EXPECTATIONS (Realistic Targets)                              │
└─────────────────────────────────────────────────────────────────────────────┘

CURRENT STATE (Pure ML):
  - Action classification: ~60% accurate
  - Track ID consistency: ~70% across game
  - Court position: ±1 meter error
  - Usable for insights: NO (too many errors)

PHASE 1 (With HITL):
  - Action classification: ~95% accurate (coach verifies)
  - Player identity: 100% accurate (coach tags)
  - Stats counts: 95%+ accurate
  - Usable for insights: YES

PHASE 3 (Improved ML + HITL):
  - Action classification: 75% accurate (ML improved)
  - Human review time: 60% reduction
  - Auto-approved segments: 50%+
  - Usable for insights: YES

LONG-TERM (Phase 4+):
  - Action classification: 85%+ accurate
  - Human review time: 75% reduction (focus on edge cases)
  - Rally outcomes: 70% auto-predicted (human confirms)
  - Usable for insights: YES

┌─────────────────────────────────────────────────────────────────────────────┐
│ 6.5 KEY STRATEGIC DECISIONS                                                │
└─────────────────────────────────────────────────────────────────────────────┘

DECISION 1: Manual vs Automated Rally Outcomes

  OPTION A: Fully automated (ball tracking)
    - Pros: Zero human effort
    - Cons: 6-8 weeks dev, 50-60% accuracy, high failure rate
    - Verdict: NOT RECOMMENDED (too hard, low ROI)

  OPTION B: Human annotation
    - Pros: 95%+ accuracy, 2-3 weeks dev, fast workflow
    - Cons: 15-20 min human time per match
    - Verdict: RECOMMENDED (best trade-off)

  OPTION C: Hybrid (ML pre-fill + human verify)
    - Pros: Reduces human time to 10 min, improves over time
    - Cons: 4-5 weeks dev, requires training data first
    - Verdict: RECOMMENDED for Phase 3

DECISION 2: Rotation Tracking Approach

  OPTION A: Fully automated
    - Pros: No human input
    - Cons: 10-12 weeks dev, 40-50% accuracy (too low)
    - Verdict: NOT RECOMMENDED

  OPTION B: Manual entry (coach enters R1-R6 per set)
    - Pros: 100% accurate, 1-2 weeks dev, <2 min per set
    - Cons: Requires coach to track rotations (they already do)
    - Verdict: RECOMMENDED

  OPTION C: Hybrid (auto-detect + manual correction)
    - Pros: Reduces entry burden
    - Cons: Complex, 6-8 weeks, still needs verification
    - Verdict: Maybe for Phase 4

DECISION 3: Ball Tracking Investment

  OPTION A: Build in-house ball tracker
    - Pros: Full control, custom for volleyball
    - Cons: 8-10 weeks dev, 50-60% accuracy, high maintenance
    - Verdict: NOT RECOMMENDED for MVP

  OPTION B: Use 3rd-party ball tracking (e.g., TrackMan, Rapsodo)
    - Pros: High accuracy (commercial systems)
    - Cons: Expensive hardware, not feasible for youth volleyball
    - Verdict: NOT FEASIBLE

  OPTION C: Skip ball tracking, use HITL for outcomes
    - Pros: Fast to market, high accuracy, low dev cost
    - Cons: Ongoing human effort (but minimal: 15 min/match)
    - Verdict: RECOMMENDED for Phases 1-3

  OPTION D: Revisit ball tracking in Phase 4 with better ML
    - Pros: More training data by then, better models available
    - Cons: Still hard
    - Verdict: MAYBE (evaluate after Phase 3 data)

DECISION 4: Coach Time Commitment (How much is acceptable?)

  BENCHMARK: What are coaches willing to do?
    - Current: Coaches spend 2-4 hours reviewing game film manually
    - With tools like Hudl: 1-2 hours tagging clips
    - Our target: <30 min per match (10x faster than manual review)

  STRATEGY:
    - Phase 1: 60 min (coach still saves 2-3 hours vs manual)
    - Phase 2: 30 min (better UX, faster workflows)
    - Phase 3: 15 min (ML automation reduces review burden)
    - Phase 4: 10 min (mostly coach notes authoring, minimal review)

  POSITIONING:
    - "Volley Moments does 95% of the work, you do the 5% only you can do"
    - Focus on value-add: insights, notes, teaching moments
    - Not on tedious: video scrubbing, counting actions, clipping

================================================================================
SECTION 7: CONCLUSION & NEXT STEPS
================================================================================

FEASIBILITY SUMMARY:

  ✓ CORE VALUE PROPOSITION IS ACHIEVABLE
    - Parent highlights and insights: YES
    - Coach analytics and tools: YES
    - Time savings for coaches: YES (10x faster than manual)

  ⚠ REQUIRES STRATEGIC HITL APPROACH
    - Pure automation not feasible with current ML state-of-the-art
    - HITL is not a compromise, it's the right architecture
    - Human judgment is the differentiator vs commodity ML

  ✗ SOME FEATURES NOT FEASIBLE (EVEN LONG-TERM)
    - Fully automated rally outcomes: too hard
    - Fully automated play classification: too complex
    - Fully automated coaching insights: requires human expertise

  ✓ BUT WORKAROUNDS ARE FAST & EFFECTIVE
    - Manual annotation UIs: 2-3 weeks to build
    - Coach time: <30 min/match (acceptable)
    - Accuracy with HITL: 95%+ (excellent)

RECOMMENDED NEXT STEPS:

  IMMEDIATE (Next 2 weeks):
    1. Validate coach willingness for HITL workflow
       - Interview 5-10 coaches
       - Ask: "Would you spend 30 min reviewing auto-analysis per match?"
       - Show mockups of review UIs

    2. Build Phase 1 MVP spec
       - Finalize feature scope
       - Design database schema
       - Create wireframes for coach + parent UIs

    3. Set up development environment
       - Frontend: React + TypeScript
       - Backend: FastAPI + PostgreSQL
       - Video: S3 + CloudFront + FFmpeg
       - Processing: Celery + Redis

  SHORT-TERM (Weeks 3-12):
    4. Build Phase 1 MVP (see roadmap above)
       - Coach review UI (identity tagging, action verification, highlight selection)
       - Parent dashboard (stats, clips, notes)
       - Video processing pipeline integration

    5. Beta test with 5-10 coaches
       - Measure: coach time per video
       - Measure: parent satisfaction
       - Collect: training data (HITL corrections)

    6. Iterate based on feedback
       - Improve UI workflows
       - Fix action classification bugs
       - Add most-requested features

  MEDIUM-TERM (Months 4-9):
    7. Build Phase 2 (rally outcomes, attack stats, coach dashboard)
    8. Scale to 30-50 coaches, 200-500 parent users
    9. Collect 1000+ hours of annotated video
    10. Begin ML model training (action classifier v2)

  LONG-TERM (Months 10-18):
    11. Build Phase 3 (ML improvements, automation)
    12. Build Phase 4 (advanced features: rotations, lineups, insights)
    13. Scale to 100s of coaches, 1000s of parents
    14. Achieve <10 min coach time per video
    15. Launch mobile app

SUCCESS CRITERIA:

  Phase 1 Success:
    - 10 active coaches using weekly
    - 50+ parents viewing dashboards
    - <60 min avg coach time per video
    - 80%+ parent satisfaction: "This is useful"

  Phase 2 Success:
    - 30 active coaches
    - 200+ parents
    - <30 min avg coach time per video
    - 90%+ stat accuracy (with HITL)

  Phase 3 Success:
    - 50+ active coaches
    - 500+ parents
    - <15 min avg coach time per video
    - 75%+ action classification accuracy (ML)

  Product-Market Fit:
    - Coaches renew subscriptions (retention >80%)
    - Parents request from coaches ("Does your team use Volley Moments?")
    - Word-of-mouth growth (coaches recruit other coaches)
    - Willingness to pay: $50-100/month per team (10-12 players)

FINAL VERDICT:

  The North Star vision IS ACHIEVABLE with a thoughtful HITL approach.

  The current architecture provides a SOLID FOUNDATION (~40% of the way there):
    ✓ Video processing pipeline
    ✓ Player detection & tracking
    ✓ Pose estimation
    ✓ Action classification (basic)
    ✓ Court detection
    ✓ Statistics aggregation
    ✓ Segment extraction

  The GAPS are ADDRESSABLE through HITL workflows (not more ML):
    ⚠ Player identity → Coach tagging
    ⚠ Action accuracy → Coach verification
    ⚠ Rally outcomes → Coach annotation
    ⚠ Insights → Coach authoring

  The TIMELINE is REALISTIC:
    - MVP in 8-10 weeks
    - Beta in 12-14 weeks
    - Full product in 9-12 months

  The VALUE PROPOSITION is STRONG:
    - Coaches save 10x time vs manual video review
    - Parents get insights they can't get anywhere else
    - Players benefit from personalized feedback

  RECOMMENDATION: Proceed with Phase 1 MVP, validate HITL workflows with beta
  coaches, iterate based on feedback, and scale with improved ML over time.

================================================================================
END OF ANALYSIS
================================================================================
